{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 순환 신경망(RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**피드포워드(feed forward) 신경망**: 단방향 신경망\n",
    "\n",
    "피드포워드 신경망은 시계열 데이터를 잘 다루지 못한다는 단점이 있다. 그래서 등장하게 된 것이 **순환 신경망(RNN)**이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 확률과 언어 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word2vec 복습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 word2vec을 확률 관점에서 바라보다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBOW 모델: 맥락으로부터 타깃을 추측\n",
    "\n",
    "윈도우 크기가 1이고 맥락을 좌우 대칭으로 생각할 때  \n",
    "$P(w_t|w_{t-1},w_{t+1})$\n",
    "\n",
    "윈도우를 왼쪽으로만 한정  \n",
    "$P(w_t|w_{t-2},w_{t-1})$  \n",
    "손실 함수(L) = $-logP(w_t|w_{t-2},w_{t-1})$, 이 값을 최소화 하는 것이 목적\n",
    "\n",
    "학습 후엔 부산물로 단어의 분산 표현을 얻을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 언어 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "언어모델(language model)은 단어 나열에 확률을 부여한다. 얼마나 자연스러운 단어 순서인지를 확률로 평가.\n",
    "\n",
    "응용 예시: 기계번역, 음성인식, 새로운 문장 생성\n",
    "\n",
    "언어 모델 수식: 동시 확률은 사후 확률의 총곱으로 나타낼 수 있다.\n",
    "\n",
    "$$\\begin {align}\n",
    "P(w_1, \\cdots, w_m) &= P(w_m|w_1, \\cdots, w_{m-1})P(w_{m-1}|w_1, \\cdots, w_{m-2}) \\cdots P(w_3|w_1,w_2)P(w_2|w_1)P(w_1) \\\\\n",
    "&= \\prod_{t=1}^mP(w_t|w_1, \\cdots, w_{t-1}) \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "확률의 곱셈정리\n",
    "\n",
    "$$P(A,B) = P(A|B)P(B) = P(B|A)P(A)$$\n",
    "\n",
    "곱셈 정리를 이용한 m개 단어의 동시 확률을 사후 확률로 표현하는 과정\n",
    "\n",
    "<img src=\"./images/e 5-6.png\" width=350>\n",
    "<img src=\"./images/e 5-7.png\" width=450>\n",
    "\n",
    "사후 확률은 타깃 단어보다 왼쪽에 있는 모든 단어를 맥락으로 했을 때의 확률이라는 의미로 볼 수 있다.\n",
    "\n",
    "언어모델을 조건부 언어모델이라고도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 CBOW 모델을 언어 모델로?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "언어모델에 적용한 CBOW 모델(근사적)\n",
    "\n",
    "$$P(w_1, \\cdots, w_m) = \\prod_{t=1}^m P(w_t|w_1, \\cdots, w_{t-1}) \\approx \\prod_{t=1}^mP(w_t|w_{t-2}, w_{t-1})$$\n",
    "\n",
    "맥락을 왼쪽 2개로 한정\n",
    "\n",
    "**마르코프 연쇄(Markov Chain)**: 미래 상태가 현재 상태에만 의존해 결정되는 것, 직전 N개의 사건에만 의존하면 N층 마르코프 연쇄\n",
    "    \n",
    "CBOW 모델의 문제점\n",
    "- 맥락의 크기가 결국 고정되어, 맥락 이전의 정보가 필요할 경우 문제를 해결할 수 없다.\n",
    "- 맥락 안의 단어 순서가 무시된다. 순서 대신 분포를 이용하기 때문이다. CBOW에선 은닉층에 단어 벡터들의 합이 전달된다.\n",
    "\n",
    "<img src=\"./images/fig%205-5.png\" width=700>\n",
    "\n",
    "순서를 고려하기 위해서 단어 벡터를 **연결(concatenat)**하는 방식을 사용한다. 신경 확률론적 언어 모델(Neural Probabilistic Language Model)에선 이 방식을 사용한다. 하지만 연결하면 매개 변수가 증가하는 문제가 생긴다.\n",
    "\n",
    "이 문제를 해결하기 위해 등장한 것이 RNN이다. RNN은 아무리 긴 맥락의 정보라도 기억할 수 있다.\n",
    "\n",
    "word2vec은 단어의 분산 표현을 얻을 목적으로 고안된 기법으로 언어 모델에 사용하는 경우는 사실 없다. 책에선 설명을 위해서 억지로 적용한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 RNN이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Neural Network(재귀 신경망)은 트리 구조의 데이터를 처리하기 위한 신경망으로 Recurrent Neural Network(순환 신경망)과는 다른 개념이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 순환하는 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN의 특징은 순환하는 경로(닫힌 경로)가 있다는 것이다. 이 덕분에 과거의 정보를 기억함과 동시에 최신 데이터를 갱신할 수 있다.\n",
    "\n",
    "<img src=\"./images/fig%205-6.png\" width=300>\n",
    "\n",
    "- $x_t$: 입력 데이터, 벡터라고 가정, 예를 들면 단어의 분산 표현\n",
    "- $t$: 시각\n",
    "- $h_t$: 입력에 대응한 출력\n",
    "- 출력은 분기되어 다시 입력으로 들어간다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 순환 구조 펼치기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig%205-8.png\" width=800>\n",
    "\n",
    "펼치면 피드 포워드 층처럼 표현이 가능하다. 하지만 각 층이 같은 계층인 것은 주의해야 한다.\n",
    "\n",
    "각 시각마다 수행하는 계산\n",
    "\n",
    "$$h_t = tanh(h_{t-1}W_h + x_tW_x + b)$$\n",
    "\n",
    "$h_{t-1}$과 $x_t$는 행 벡터이다. 현재의 출력($h_t$)는 이전 출력($h_{t-1}$)에 기초해서 계산된다. RNN는 h라는 상태를 갖고 이를 통해 갱신이 된다고 해석할 수 있다. 그래서 RNN을 상태, 메모리를 가지는 계층이라고 부른다.\n",
    "\n",
    "$h_t$를 은닉 상태, 은닉 상태 벡터라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 BPTT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig%205-10.png\" width=800>\n",
    "\n",
    "**BPTT(backpropagation through time)**: 시간 방향으로 펼친 신경망의 오차역전파법, 일반적인 오차역전파법처럼 적용할 수 있다.\n",
    "\n",
    "#### 문제\n",
    "- 시간에 비례해서 커지는 컴퓨팅 자원, ex) 메모리 사용량 증가, 계산량 증가\n",
    "- 시간에 비례해서 불안정해지는 기울기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.4 Truncated BPTT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "큰 시계열 데이터를 적당한 길이로 끊어 여러 작은 신경망으로 만든 후 오차역전파법을 수행하는 방법이다. 단, **역전파의 연결만 끊고, 순전파는 그대로 유지해야 한다.** 입력 데이터는 순서대로 넣어줘야 한다.\n",
    "\n",
    "<img src=\"./images/fig%205-14.png\">\n",
    "\n",
    "다음 블록에서 이전 블록의 마지막 은닉 상태를 이용해서 각 블록을 순서대로 연결할 수 있도록 한다. 역전파는 각 블록을 단위로 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.5 Truncated BPTT의 미니배치 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미니배치의 시작 위치를 오프셋으로 옮겨준 후에 순서대로 데이터를 입력하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 RNN 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가로로 펼친 RNN은 여러 입력과 출력을 묶어 하나의 계층으로 볼 수 있고, 책에선 여러 단계의 작업을 한꺼번에 처리할 때 앞에 Time을 붙여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 RNN 계층 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순전파\n",
    "\n",
    "$$h_t = tanh(h_{t-1}W_h + x_tW_x + b)$$\n",
    "\n",
    "데이터는 미니배치로 처리한다.\n",
    "\n",
    "<img src=\"./images/fig%205-18.png\" width=600>\n",
    "<img src=\"./images/fig%205-19.png\" width=600>\n",
    "<img src=\"./images/fig%205-20.png\" width=600>\n",
    "\n",
    "tanh 미분\n",
    "\n",
    "$$y = tanh(x)$$\n",
    "\n",
    "$$\\frac {dy} {dx} = 1 - y^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    \n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None    # 역전파 계산 시 사용하는 중간 데이터\n",
    "        \n",
    "    \n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        t = np.matmul(h_prev, Wh) + np.matmul(x, Wx) + b\n",
    "        h_next = np.tanh(t)\n",
    "        \n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        \n",
    "        return h_next\n",
    "    \n",
    "    \n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "        \n",
    "        dt = dh_next * (1 - h_next**2)\n",
    "        db = np.sum(dt, axis=0)\n",
    "        dWh = np.matmul(h_prev.T, dt)\n",
    "        dh_prev = np.matmul(dt, Wh.T)\n",
    "        dWx = np.matmul(x.T, dt)\n",
    "        dx = np.matmul(dt, Wx.T)\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "        \n",
    "        return dx, dh_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Time RNN 계층 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T개의 RNN 계층으로 구현\n",
    "\n",
    "<img src=\"./images/fig%205-22.png\" width=800>\n",
    "<img src=\"./images/fig%205-23.png\" width=700>\n",
    "<img src=\"./images/fig%205-24.png\" width=700>\n",
    "\n",
    "순전파에서 출력이 2개로 분기되기 때문에 역전파에서는 각 기울기가 합산되어 전해진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "    \n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        \n",
    "        self.h, self.dh = None, None\n",
    "        self.stateful = stateful\n",
    "    \n",
    "    \n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "        \n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.h = None\n",
    "        \n",
    "        \n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "        \n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "            \n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params)\n",
    "            self.h = layer.forward(xs[:, t, :], self.h)\n",
    "            hs[:, t, :] = self.h\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        return hs\n",
    "    \n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(dhs[:, t, :] + dh)\n",
    "            dxs[:, t, :] = dx\n",
    "            \n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "                \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        \n",
    "        return dxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h는 forward를 불렀을 때 마지막 은닉 상태를 저장, dh는 backward를 불렀을 때 하나 앞 블록의 은닉 상태의 기울기를 저장한다.  \n",
    "stateful은 은닉 상태를 유지할지 정하는 인수, True: 은닉 상태 유지, False: 은닉상태를 영행렬로 초기화(무상태), 긴 시계열 데이터를 처리할 때 은닉 상태를 유지해야 한다.\n",
    "\n",
    "Time RNN 계층의 최종 가중치의 기울기는 각 RNN 계층의 가중치 기울기를 모두 더한 게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 시계열 데이터 처리 계층 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 RNNLM의 전체 그림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig%205-25.png\" width=700>\n",
    "\n",
    "RNN 계층이 있어서 과거에서 현재로 데이터를 계속 흘려보내줌으로써 과거의 정보를 인코딩해 기억할 수 있다. RNNLM은 지금까지 입력된 단어를 기억하고 그것을 바탕으로 다음에 출현할 단어를 예측한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 Time 계층 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Affine 계층: Affine 계층을 T개 준비해서, 각 시각의 데이터를 개별적으로 처리한다.\n",
    "\n",
    "Time Embedding 계층: Embedding 계층을 T개 준비하고 각 시각의 데이터를 개별적으로 처리한다.\n",
    "\n",
    "Affine과 Embedding 계층은 코드로 구현할 땐 행렬 계산으로 한꺼번에 처리한다.\n",
    "\n",
    "<img src=\"./images/fig%205-29.png\" width=700>\n",
    "\n",
    "$$L = \\frac 1 T (L_0 + L_1 + \\cdots + L_{t-1})$$\n",
    "\n",
    "Time Softmax with Loss 계층도 미니배치를 처리하기 때문에 N개의 손실을 더해 다시 N으로 나눠 데이터 1개당 평균 손실을 최종 출력으로 내보낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 RNNLM 학습과 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.1 RNNLM 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig%205-30.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from common.time_layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRnnlm:\n",
    "    \n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        # RNN, Affine 계층은 Xavier 초깃값 사용: 이전 계층의 노드가 n개일때 1/sqrt(n)을 표준편차인 분포로 초기화\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D).astype('f'))\n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H).astype('f'))\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H).astype('f'))\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),    # Truncated RNN으로 학습\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "        \n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "        \n",
    "    def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "            \n",
    "        return dout\n",
    "    \n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치 초깃값으로 0.01 * np.random.uniform()처럼 스케일을 변환한 균일분포를 이용하는 경우도 많다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 언어 모델의 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**퍼플렉서티(perplexity, 혼란도)**: 간단히 학률의 역수(입력이 하나일 경우), 퍼플렉서티는 낮을수록 좋다.\n",
    "\n",
    "퍼플렉서티를 비교할 때 분기 수(number of branches)로 해석할 수 있고, 이는 다음에 취할 수 있는 선택사항의 수를 말한다. 만약 1.25라면 다음에 출현할 단어의 후보를 거의 1개 정도로 좁혔다고 볼 수 있고, 5인 경우에는 후보가 아직 5개나 된다는 것을 의미한다.\n",
    "\n",
    "입력이 여러 개일 때의 퍼플렉서티\n",
    "\n",
    "$$L = -\\frac 1 N \\sum_n\\sum_k t_{nk}logy_{nk}$$\n",
    "\n",
    "$$perplexity = e^L$$\n",
    "\n",
    "L은 신경망의 손실을 뜻한다. 데이터가 하나일 때의 의미는 모두 일맥상통한다.\n",
    "\n",
    "정보이론 분야에서는 퍼플렉서티를 기하평균 분기 수라고도 한다. 분기 수를 데이터가 N개인 경우에 평균한 것으로 해석할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.3 RNNLM의 학습 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PTB 데이터셋으로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common.optimizer import Adam\n",
    "from dataset import ptb\n",
    "from simple_rnnlm import SimpleRnnlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말뭉치 크기: 1000, 어휘 수: 418\n",
      "| 에폭 1 | 퍼플렉서티 398.50\n",
      "| 에폭 2 | 퍼플렉서티 243.60\n",
      "| 에폭 3 | 퍼플렉서티 196.28\n",
      "| 에폭 4 | 퍼플렉서티 186.40\n",
      "| 에폭 5 | 퍼플렉서티 174.51\n",
      "| 에폭 6 | 퍼플렉서티 165.44\n",
      "| 에폭 7 | 퍼플렉서티 150.12\n",
      "| 에폭 8 | 퍼플렉서티 132.66\n",
      "| 에폭 9 | 퍼플렉서티 109.21\n",
      "| 에폭 10 | 퍼플렉서티 89.49\n",
      "| 에폭 11 | 퍼플렉서티 72.67\n",
      "| 에폭 12 | 퍼플렉서티 58.22\n",
      "| 에폭 13 | 퍼플렉서티 45.84\n",
      "| 에폭 14 | 퍼플렉서티 35.92\n",
      "| 에폭 15 | 퍼플렉서티 28.62\n",
      "| 에폭 16 | 퍼플렉서티 22.78\n",
      "| 에폭 17 | 퍼플렉서티 17.91\n",
      "| 에폭 18 | 퍼플렉서티 14.20\n",
      "| 에폭 19 | 퍼플렉서티 11.62\n",
      "| 에폭 20 | 퍼플렉서티 9.60\n",
      "| 에폭 21 | 퍼플렉서티 7.94\n",
      "| 에폭 22 | 퍼플렉서티 6.71\n",
      "| 에폭 23 | 퍼플렉서티 5.59\n",
      "| 에폭 24 | 퍼플렉서티 4.78\n",
      "| 에폭 25 | 퍼플렉서티 4.11\n",
      "| 에폭 26 | 퍼플렉서티 3.62\n",
      "| 에폭 27 | 퍼플렉서티 3.18\n",
      "| 에폭 28 | 퍼플렉서티 2.82\n",
      "| 에폭 29 | 퍼플렉서티 2.56\n",
      "| 에폭 30 | 퍼플렉서티 2.31\n",
      "| 에폭 31 | 퍼플렉서티 2.13\n",
      "| 에폭 32 | 퍼플렉서티 1.97\n",
      "| 에폭 33 | 퍼플렉서티 1.84\n",
      "| 에폭 34 | 퍼플렉서티 1.73\n",
      "| 에폭 35 | 퍼플렉서티 1.65\n",
      "| 에폭 36 | 퍼플렉서티 1.57\n",
      "| 에폭 37 | 퍼플렉서티 1.50\n",
      "| 에폭 38 | 퍼플렉서티 1.45\n",
      "| 에폭 39 | 퍼플렉서티 1.40\n",
      "| 에폭 40 | 퍼플렉서티 1.36\n",
      "| 에폭 41 | 퍼플렉서티 1.33\n",
      "| 에폭 42 | 퍼플렉서티 1.30\n",
      "| 에폭 43 | 퍼플렉서티 1.28\n",
      "| 에폭 44 | 퍼플렉서티 1.25\n",
      "| 에폭 45 | 퍼플렉서티 1.23\n",
      "| 에폭 46 | 퍼플렉서티 1.21\n",
      "| 에폭 47 | 퍼플렉서티 1.20\n",
      "| 에폭 48 | 퍼플렉서티 1.18\n",
      "| 에폭 49 | 퍼플렉서티 1.17\n",
      "| 에폭 50 | 퍼플렉서티 1.16\n",
      "| 에폭 51 | 퍼플렉서티 1.15\n",
      "| 에폭 52 | 퍼플렉서티 1.14\n",
      "| 에폭 53 | 퍼플렉서티 1.13\n",
      "| 에폭 54 | 퍼플렉서티 1.12\n",
      "| 에폭 55 | 퍼플렉서티 1.12\n",
      "| 에폭 56 | 퍼플렉서티 1.11\n",
      "| 에폭 57 | 퍼플렉서티 1.11\n",
      "| 에폭 58 | 퍼플렉서티 1.10\n",
      "| 에폭 59 | 퍼플렉서티 1.10\n",
      "| 에폭 60 | 퍼플렉서티 1.09\n",
      "| 에폭 61 | 퍼플렉서티 1.09\n",
      "| 에폭 62 | 퍼플렉서티 1.08\n",
      "| 에폭 63 | 퍼플렉서티 1.08\n",
      "| 에폭 64 | 퍼플렉서티 1.08\n",
      "| 에폭 65 | 퍼플렉서티 1.07\n",
      "| 에폭 66 | 퍼플렉서티 1.07\n",
      "| 에폭 67 | 퍼플렉서티 1.07\n",
      "| 에폭 68 | 퍼플렉서티 1.06\n",
      "| 에폭 69 | 퍼플렉서티 1.06\n",
      "| 에폭 70 | 퍼플렉서티 1.06\n",
      "| 에폭 71 | 퍼플렉서티 1.06\n",
      "| 에폭 72 | 퍼플렉서티 1.06\n",
      "| 에폭 73 | 퍼플렉서티 1.05\n",
      "| 에폭 74 | 퍼플렉서티 1.05\n",
      "| 에폭 75 | 퍼플렉서티 1.05\n",
      "| 에폭 76 | 퍼플렉서티 1.05\n",
      "| 에폭 77 | 퍼플렉서티 1.05\n",
      "| 에폭 78 | 퍼플렉서티 1.04\n",
      "| 에폭 79 | 퍼플렉서티 1.04\n",
      "| 에폭 80 | 퍼플렉서티 1.04\n",
      "| 에폭 81 | 퍼플렉서티 1.04\n",
      "| 에폭 82 | 퍼플렉서티 1.04\n",
      "| 에폭 83 | 퍼플렉서티 1.04\n",
      "| 에폭 84 | 퍼플렉서티 1.04\n",
      "| 에폭 85 | 퍼플렉서티 1.04\n",
      "| 에폭 86 | 퍼플렉서티 1.03\n",
      "| 에폭 87 | 퍼플렉서티 1.03\n",
      "| 에폭 88 | 퍼플렉서티 1.03\n",
      "| 에폭 89 | 퍼플렉서티 1.03\n",
      "| 에폭 90 | 퍼플렉서티 1.03\n",
      "| 에폭 91 | 퍼플렉서티 1.03\n",
      "| 에폭 92 | 퍼플렉서티 1.03\n",
      "| 에폭 93 | 퍼플렉서티 1.03\n",
      "| 에폭 94 | 퍼플렉서티 1.03\n",
      "| 에폭 95 | 퍼플렉서티 1.03\n",
      "| 에폭 96 | 퍼플렉서티 1.03\n",
      "| 에폭 97 | 퍼플렉서티 1.03\n",
      "| 에폭 98 | 퍼플렉서티 1.03\n",
      "| 에폭 99 | 퍼플렉서티 1.02\n",
      "| 에폭 100 | 퍼플렉서티 1.02\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100\n",
    "time_size = 5    # Truncated BPTT가 한 번에 펼치는 시간 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습 데이터 읽기(전체 중 1000개만)\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1]    # 입력\n",
    "ts = corpus[1:]     # 출력(정답 레이블)\n",
    "data_size = len(xs)\n",
    "print('말뭉치 크기: %d, 어휘 수: %d' % (corpus_size, vocab_size))\n",
    "\n",
    "# 학습 시 사용하는 변수\n",
    "max_iters = data_size // (batch_size * time_size)\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []\n",
    "\n",
    "# 모델 생성\n",
    "model  = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = Adam()\n",
    "\n",
    "# 각 미니배치에서 샘플을 읽기 시작 위치를 계산\n",
    "jump = (corpus_size - 1) // batch_size\n",
    "offsets = [i * jump for i in range(batch_size)]\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # 미니배치 획득\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "        \n",
    "        # 기울기를 구하여 매개변수 갱신\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "        \n",
    "    # 에폭마다 퍼플렉서티 평가\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| 에폭 %d | 퍼플렉서티 %.2f' % (epoch+1, ppl))\n",
    "    ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "1 0 99\n",
      "2 0 198\n",
      "3 0 297\n",
      "4 0 396\n",
      "5 0 495\n",
      "6 0 594\n",
      "7 0 693\n",
      "8 0 792\n",
      "9 0 891\n",
      "\n",
      "0 1 1\n",
      "1 1 100\n",
      "2 1 199\n",
      "3 1 298\n",
      "4 1 397\n",
      "5 1 496\n",
      "6 1 595\n",
      "7 1 694\n",
      "8 1 793\n",
      "9 1 892\n",
      "\n",
      "0 2 2\n",
      "1 2 101\n",
      "2 2 200\n",
      "3 2 299\n",
      "4 2 398\n",
      "5 2 497\n",
      "6 2 596\n",
      "7 2 695\n",
      "8 2 794\n",
      "9 2 893\n",
      "\n",
      "0 3 3\n",
      "1 3 102\n",
      "2 3 201\n",
      "3 3 300\n",
      "4 3 399\n",
      "5 3 498\n",
      "6 3 597\n",
      "7 3 696\n",
      "8 3 795\n",
      "9 3 894\n",
      "\n",
      "0 4 4\n",
      "1 4 103\n",
      "2 4 202\n",
      "3 4 301\n",
      "4 4 400\n",
      "5 4 499\n",
      "6 4 598\n",
      "7 4 697\n",
      "8 4 796\n",
      "9 4 895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 배치를 어떻게 뽑아오는지 알아보기 위해서\n",
    "time_idx = 0\n",
    "for t in range(time_size):\n",
    "    for i, offset in enumerate(offsets):\n",
    "        print(i, t, (offset + time_idx) % data_size)\n",
    "    print()\n",
    "    time_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(max_epoch), ppl_list)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"perplexity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0241756093884897"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl_list[-1] # optimizer을 adam으로만 바꿨는데 퍼플렉서티가 더욱 낮아졌다. SGD의 경우에는 5에 가까웠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 진행할 수록 퍼플렉서티가 순조롭게 낮아지고 있다. 하지만 큰 말뭉치에는 대응할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.4 RNNLM의 Trainer 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RnnlmTrainer 클래스를 사용하면 학습을 클래스 안으로 숨길 수 있다. fit() 메소드를 호출해서 학습을 수행한다.\n",
    "\n",
    "학습 수행 과정\n",
    "1. 미니배치를 '순차적'으로 만든다.\n",
    "2. 모델의 순전파와 역전파를 호출한다\n",
    "3. 옵티마이저로 가중치를 갱신한다.\n",
    "4. 퍼플렉서티를 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 420.49\n",
      "| 에폭 2 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 400.28\n",
      "| 에폭 3 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 305.56\n",
      "| 에폭 4 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 229.15\n",
      "| 에폭 5 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 213.35\n",
      "| 에폭 6 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 210.87\n",
      "| 에폭 7 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 202.08\n",
      "| 에폭 8 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 201.18\n",
      "| 에폭 9 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 195.49\n",
      "| 에폭 10 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 191.02\n",
      "| 에폭 11 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 193.01\n",
      "| 에폭 12 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 188.90\n",
      "| 에폭 13 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 192.84\n",
      "| 에폭 14 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 187.48\n",
      "| 에폭 15 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 187.09\n",
      "| 에폭 16 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 190.57\n",
      "| 에폭 17 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 187.82\n",
      "| 에폭 18 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 183.28\n",
      "| 에폭 19 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 180.21\n",
      "| 에폭 20 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 180.50\n",
      "| 에폭 21 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 177.17\n",
      "| 에폭 22 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 176.30\n",
      "| 에폭 23 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 179.84\n",
      "| 에폭 24 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 176.50\n",
      "| 에폭 25 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 169.41\n",
      "| 에폭 26 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 171.57\n",
      "| 에폭 27 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 167.92\n",
      "| 에폭 28 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 169.86\n",
      "| 에폭 29 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 162.57\n",
      "| 에폭 30 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 157.67\n",
      "| 에폭 31 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 156.30\n",
      "| 에폭 32 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 149.09\n",
      "| 에폭 33 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 150.10\n",
      "| 에폭 34 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 148.43\n",
      "| 에폭 35 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 142.15\n",
      "| 에폭 36 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 138.88\n",
      "| 에폭 37 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 138.50\n",
      "| 에폭 38 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 131.27\n",
      "| 에폭 39 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 125.76\n",
      "| 에폭 40 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 121.42\n",
      "| 에폭 41 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 118.80\n",
      "| 에폭 42 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 116.74\n",
      "| 에폭 43 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 110.38\n",
      "| 에폭 44 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 107.09\n",
      "| 에폭 45 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 98.82\n",
      "| 에폭 46 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 97.56\n",
      "| 에폭 47 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 95.26\n",
      "| 에폭 48 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 89.95\n",
      "| 에폭 49 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 86.71\n",
      "| 에폭 50 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 79.92\n",
      "| 에폭 51 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 78.54\n",
      "| 에폭 52 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 73.68\n",
      "| 에폭 53 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 70.33\n",
      "| 에폭 54 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 66.14\n",
      "| 에폭 55 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 63.41\n",
      "| 에폭 56 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 60.69\n",
      "| 에폭 57 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 59.80\n",
      "| 에폭 58 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 52.97\n",
      "| 에폭 59 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 51.19\n",
      "| 에폭 60 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 49.32\n",
      "| 에폭 61 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 43.89\n",
      "| 에폭 62 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 41.69\n",
      "| 에폭 63 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 40.80\n",
      "| 에폭 64 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 38.33\n",
      "| 에폭 65 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 35.27\n",
      "| 에폭 66 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 33.34\n",
      "| 에폭 67 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 31.71\n",
      "| 에폭 68 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 30.72\n",
      "| 에폭 69 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 29.86\n",
      "| 에폭 70 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 27.32\n",
      "| 에폭 71 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 25.28\n",
      "| 에폭 72 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 24.53\n",
      "| 에폭 73 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 23.71\n",
      "| 에폭 74 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 21.53\n",
      "| 에폭 75 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 20.81\n",
      "| 에폭 76 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 19.39\n",
      "| 에폭 77 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 18.17\n",
      "| 에폭 78 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 17.30\n",
      "| 에폭 79 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 16.66\n",
      "| 에폭 80 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 15.81\n",
      "| 에폭 81 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 14.51\n",
      "| 에폭 82 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 13.52\n",
      "| 에폭 83 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 12.98\n",
      "| 에폭 84 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 12.50\n",
      "| 에폭 85 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 12.09\n",
      "| 에폭 86 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 11.48\n",
      "| 에폭 87 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 10.73\n",
      "| 에폭 88 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 10.35\n",
      "| 에폭 89 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 9.84\n",
      "| 에폭 90 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 9.34\n",
      "| 에폭 91 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 9.14\n",
      "| 에폭 92 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 8.43\n",
      "| 에폭 93 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 7.71\n",
      "| 에폭 94 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 7.47\n",
      "| 에폭 95 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 7.04\n",
      "| 에폭 96 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 6.92\n",
      "| 에폭 97 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 6.56\n",
      "| 에폭 98 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 6.05\n",
      "| 에폭 99 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 5.85\n",
      "| 에폭 100 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 5.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KJK\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\KJK\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\KJK\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\KJK\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\KJK\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\KJK\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\KJK\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\KJK\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\KJK\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\KJK\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\KJK\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\KJK\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\KJK\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\KJK\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from dataset import ptb\n",
    "from simple_rnnlm import SimpleRnnlm\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 5  # RNN을 펼치는 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000  # 테스트 데이터셋을 작게 설정\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "xs = corpus[:-1]  # 입력\n",
    "ts = corpus[1:]  # 출력（정답 레이블）\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size)\n",
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.7043586902585375"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.ppl_list[-1] # SGD를 사용한 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
