{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8. 어텐션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 어텐션의 구조\n",
    "* 어텐션 : seq2seq를 필요한 정보에만 주목하게 함.\n",
    "    * 이를 통해 seq2seq가 갖고 있는 문제를 해결 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seq2seq의 문제점\n",
    "* 이전의 seq2seq는 Encoder가 고정 길이의 벡터를 출력  \n",
    "    * 아무리 긴 문장이 있더라도 고정된 길이의 벡터로 반환해야 하기 때문에 한계가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder 개선\n",
    "* 시각 별 LSTM 계층의 은닉 상태 벡터를 모두 사용 : 이렇게 되면 입력된 단어 길이와 같은 수의 벡터를 얻을 수 있다. \n",
    "* 여러 딥러닝 프레임워크에서 RNN 계층을 초기화할 때 모든 시각의 은닉 상태 벡터 변환과 마지막 은닉 상태 벡터만 반환 둘 중 하나로 설정할 수 있다.\n",
    "* 각 시각의 은닉 상태에는 해당 시각에 입력된 단어의 정보가 많이 담겨 있을 것이다.\n",
    "* 문장에서 단어의 정보는 주변 정보를 균형 있게 담아야 하기 때문에 양방향 RNN이나 양방향 LSTM을 사용하면 효과적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder 개선 1\n",
    "* **얼라인먼트(alignment)**: 단어(혹은 문구)의 대응 관계를 나타내는 정보, 이전까지는 사람의 수작업으로 만들어졌다. \n",
    "    * 어텐션 : 얼라인먼트 자동으로 수행\n",
    "\n",
    "* 어텐션 : 필요한 정보에만 주목해서 그 정보로부터 시계열 변환을 수행\n",
    "\n",
    "<img src='./images/fig_8-6.png' width=700>\n",
    "\n",
    "* 입력 : Encoder로부터 온 hs와 시각별 LSTM 계층의 은닉 상태이다. \n",
    "    * 필요한 정보만 골라 Affine 계층으로 출력한다.\n",
    "    * Encoder의 마지막 은닉 상태 벡터 : Decoder의 첫번째 LSTM 계층로 전달된다.\n",
    "\n",
    "* Decoder에서 출력을 할 때 필요한 정보를 hs에서 선택하는 과정이다. \n",
    "    * 하지만 선택하는 작업은 미분할 수 없다는 문제 발생\n",
    "    * 이 문제를 **전체를 선택한 후 각 단어의 가중치를 별도로 계산하는 문제로 치환**하면 미분 가능\n",
    "\n",
    "<img src=\"./images/fig_8-8.png\" width=600>\n",
    "\n",
    "* 각 단어의 중요도를 나타내는 가중치 a(확률분포와 유사)를 구한 후 단어 벡터 hs와 가중합을 계산해서 맥락 벡터 c를 구한다. \n",
    "    * '나'에 대응하는 가중치가 0.8이었으니 맥락 벡터에는 '나' 벡터의 성분이 많이 포함된 걸로 해석 가능\n",
    "    * 맥락 벡터 c : 현 시각의 변환을 수행하는데 필요한 정보가 담겨야 한다.\n",
    "    * 결국 이렇게 학습하도록하는 것이 궁극적인 목표이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n",
      "(5, 4)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "T, H = 5, 4\n",
    "hs = np.random.randn(T, H)\n",
    "a = np.array([0.8, 0.1, 0.03, 0.05, 0.02])\n",
    "\n",
    "ar = a.reshape(5, 1).repeat(4, axis=1)\n",
    "print(ar.shape)\n",
    "\n",
    "t = hs * ar\n",
    "print(t.shape)\n",
    "\n",
    "c = np.sum(t, axis=0)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 4)\n",
      "(10, 4)\n"
     ]
    }
   ],
   "source": [
    "# 미니배치 처리 : 가중합 구현\n",
    "N, T, H = 10, 5, 4\n",
    "hs = np.random.randn(N, T, H)\n",
    "a = np.random.randn(N, T)\n",
    "ar = a.reshape(N, T, 1).repeat(H, axis=2)\n",
    "# ar = a.reshape(N, T, 1) # 브로드캐스트를 사용하는 경우\n",
    "\n",
    "t = hs * ar\n",
    "print(t.shape)\n",
    "\n",
    "c = np.sum(t, axis=1)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightSum:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.cache = None\n",
    "        \n",
    "        \n",
    "    def forward(self, hs, a):\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        ar = a.reshape(N, T, 1).repeat(H, axis=2)\n",
    "        t = hs * ar\n",
    "        c = np.sum(t, axis=1)\n",
    "        \n",
    "        self.cache = (hs, ar)\n",
    "        \n",
    "        return c\n",
    "    \n",
    "    \n",
    "    def backward(self, dc):\n",
    "        hs, ar = self.cache\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        dt = dc.reshape(N, 1, H).repeat(T, axis=1)\n",
    "        dar = dt * hs\n",
    "        dhs = dt * ar\n",
    "        da = np.sum(dar, axis=2)\n",
    "        \n",
    "        return dhs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder 개선 2\n",
    "* 가중치 a도 데이터로부터 자동으로 학습할 수 있도록 해야 한다.\n",
    "* Decoder의 LSTM 계층의 은닉 상태 벡터(h)와 Encoder의 마지막 시각의 hs 사이의 유사도는 벡터의 내적으로 구할 수 있다. \n",
    "    * 내적은 두 벡터가 얼마나 같은 방향을 향하고 있는지를 나타낸다. 내적을 하면 정규화하기 전의 점수 s를 구할 수 있다. \n",
    "* s는 일반적으로 소프트맥스 함수를 거쳐 정규화해 가중치 a를 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 4)\n",
      "(10, 5)\n",
      "(10, 5)\n"
     ]
    }
   ],
   "source": [
    "from common.layers import Softmax\n",
    "import numpy as np\n",
    "N, T, H = 10, 5, 4\n",
    "hs = np.random.randn(N, T, H)\n",
    "h = np.random.randn(N, H)\n",
    "hr = h.reshape(N, 1, H)\n",
    "\n",
    "t = hs * hr\n",
    "print(t.shape)\n",
    "\n",
    "s = np.sum(t, axis=2)\n",
    "print(s.shape)\n",
    "\n",
    "softmax = Softmax()\n",
    "a = softmax.forward(s)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.np import *\n",
    "from common.layers import Softmax\n",
    "\n",
    "class AttentionWeight:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.softmax = Softmax()\n",
    "        self.cache = None\n",
    "        \n",
    "    \n",
    "    def forward(self, hs, h):\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        hr = h.reshape(N, 1, H).repeat(T, axis=1)\n",
    "        t = hs * hr\n",
    "        s = np.sum(t, axis=2)\n",
    "        a = self.softmax.forward(s)\n",
    "        \n",
    "        self.cache = (hs, hr)\n",
    "        return a\n",
    "    \n",
    "    \n",
    "    def backward(self, da):\n",
    "        hs, hr = self.cache\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        ds = self.softmax.backward(da)\n",
    "        dt = ds.reshape(N, T, 1).repeat(H, axis=2)\n",
    "        dhs = dt * hr\n",
    "        dhr = dt * hs\n",
    "        dh = np.sum(dhr, axis=1)\n",
    "        \n",
    "        return dhs, dh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder 개선 3\n",
    "\n",
    "<img src=\"./images/fig_8-16.png\" width=600>\n",
    "\n",
    "현재까지 Weight Sum, Attention Weight 게층이라고 하고, 이 둘을 합쳐서 Attention 계층이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.attention_weight_layer = AttentionWeight()\n",
    "        self.weight_sum_layer = WeightSum()\n",
    "        self.attention_weight = None\n",
    "        \n",
    "        \n",
    "    def forward(self, hs, h):\n",
    "        a = self.attention_weight_layer.forward(hs, h)\n",
    "        out = self.weight_sum_layer.forward(hs, a)\n",
    "        self.attention_weight = a\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dhs0, da = self.weight_sum_layer.backward(dout)\n",
    "        dhs1, dh = self.attention_weight_layer.backward(da)\n",
    "        dhs = dhs0 + dhs1\n",
    "        \n",
    "        return dhs, dh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_8-18.png\" width=700>\n",
    "\n",
    "* Affine 계층에 맥락 벡터와 은닉 상태 벡터가 입력\n",
    "* 다수의 Attention 계층을 모아 Time Attention 계층 구현 가능\n",
    "\n",
    "<img src=\"./images/fig_8-20.png\" width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeAttention:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.layers = None\n",
    "        self.attention_weights = None\n",
    "\n",
    "    def forward(self, hs_enc, hs_dec):\n",
    "        N, T, H = hs_dec.shape\n",
    "        out = np.empty_like(hs_dec)\n",
    "        self.layers = []\n",
    "        self.attention_weights = []\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = Attention()\n",
    "            out[:, t, :] = layer.forward(hs_enc, hs_dec[:,t,:])\n",
    "            self.layers.append(layer)\n",
    "            self.attention_weights.append(layer.attention_weight)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        N, T, H = dout.shape\n",
    "        dhs_enc = 0\n",
    "        dhs_dec = np.empty_like(dout)\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            dhs, dh = layer.backward(dout[:, t, :])\n",
    "            dhs_enc += dhs\n",
    "            dhs_dec[:,t,:] = dh\n",
    "\n",
    "        return dhs_enc, dhs_dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 어텐션을 갖춘 seq2seq 구현\n",
    "### Encoder 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from seq2seq import Encoder, Seq2seq\n",
    "from attention_layer import TimeAttention\n",
    "\n",
    "\n",
    "class AttentionEncoder(Encoder):\n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dout)\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(2*H, V) / np.sqrt(2*H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
    "        self.attention = TimeAttention()\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "        layers = [self.embed, self.lstm, self.attention, self.affine]\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, enc_hs):\n",
    "        h = enc_hs[:,-1]\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        out = self.embed.forward(xs)\n",
    "        dec_hs = self.lstm.forward(out)\n",
    "        c = self.attention.forward(enc_hs, dec_hs)\n",
    "        out = np.concatenate((c, dec_hs), axis=2)\n",
    "        score = self.affine.forward(out)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        dout = self.affine.backward(dscore)\n",
    "        N, T, H2 = dout.shape\n",
    "        H = H2 // 2\n",
    "\n",
    "        dc, ddec_hs0 = dout[:,:,:H], dout[:,:,H:]\n",
    "        denc_hs, ddec_hs1 = self.attention.backward(dc)\n",
    "        ddec_hs = ddec_hs0 + ddec_hs1\n",
    "        dout = self.lstm.backward(ddec_hs)\n",
    "        dh = self.lstm.dh\n",
    "        denc_hs[:, -1] += dh\n",
    "        self.embed.backward(dout)\n",
    "\n",
    "        return denc_hs\n",
    "\n",
    "    def generate(self, enc_hs, start_id, sample_size):\n",
    "        sampled = []\n",
    "        sample_id = start_id\n",
    "        h = enc_hs[:, -1]\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        for _ in range(sample_size):\n",
    "            x = np.array([sample_id]).reshape((1, 1))\n",
    "\n",
    "            out = self.embed.forward(x)\n",
    "            dec_hs = self.lstm.forward(out)\n",
    "            c = self.attention.forward(enc_hs, dec_hs)\n",
    "            out = np.concatenate((c, dec_hs), axis=2)\n",
    "            score = self.affine.forward(out)\n",
    "\n",
    "            sample_id = np.argmax(score.flatten())\n",
    "            sampled.append(sample_id)\n",
    "\n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seq2seq 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionSeq2seq(Seq2seq):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        args = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = AttentionEncoder(*args)\n",
    "        self.decoder = AttentionDecoder(*args)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "\n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 어텐션 평가\n",
    "### 날짜 형식 변환 문제  \n",
    "\n",
    "* 번역용 데이터셋 : WMT\n",
    "    * 너무 커서 날짜 형식 변경 문제로 대체\n",
    "    \n",
    "* 사람이 쓴 날짜 데이터(형식에 맞추지 않음)를 표준 형식(YYYY-MM-DD)으로 변환\n",
    "\n",
    "    * 사람이 쓴 날짜 데이터의 형식은 매우 많으므로 수작업으로 해당 패턴을 찾아서 변환 규칙을 만드는 것은 매우 번거롭다.  \n",
    "    * 입력과 출력의 대응 관계를 쉽게 알 수 있다.\n",
    "\n",
    "<img src=\"./images/fig_8-23.png\" width=500>\n",
    "\n",
    "* 입력과 출력의 구분 문자는 \\_, 출력의 끝은 출력의 길이가 모두 동일해서 따로 두지 않았다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어텐션을 갖춘 seq2seq의 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataset import sequence\n",
    "from common.optimizer import SGD\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n",
    "from attention_seq2seq import AttentionSeq2seq\n",
    "from seq2seq import Seq2seq\n",
    "from peeky_seq2seq import PeekySeq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 351 | 시간 0[s] | 손실 4.08\n",
      "| 에폭 1 |  반복 21 / 351 | 시간 6[s] | 손실 4.06\n",
      "| 에폭 1 |  반복 41 / 351 | 시간 12[s] | 손실 4.03\n",
      "| 에폭 1 |  반복 61 / 351 | 시간 19[s] | 손실 4.00\n",
      "| 에폭 1 |  반복 81 / 351 | 시간 25[s] | 손실 3.97\n",
      "| 에폭 1 |  반복 101 / 351 | 시간 31[s] | 손실 3.93\n",
      "| 에폭 1 |  반복 121 / 351 | 시간 37[s] | 손실 3.90\n",
      "| 에폭 1 |  반복 141 / 351 | 시간 43[s] | 손실 3.87\n",
      "| 에폭 1 |  반복 161 / 351 | 시간 49[s] | 손실 3.84\n",
      "| 에폭 1 |  반복 181 / 351 | 시간 55[s] | 손실 3.80\n",
      "| 에폭 1 |  반복 201 / 351 | 시간 61[s] | 손실 3.77\n",
      "| 에폭 1 |  반복 221 / 351 | 시간 67[s] | 손실 3.73\n",
      "| 에폭 1 |  반복 241 / 351 | 시간 73[s] | 손실 3.69\n",
      "| 에폭 1 |  반복 261 / 351 | 시간 79[s] | 손실 3.65\n",
      "| 에폭 1 |  반복 281 / 351 | 시간 85[s] | 손실 3.61\n",
      "| 에폭 1 |  반복 301 / 351 | 시간 91[s] | 손실 3.56\n",
      "| 에폭 1 |  반복 321 / 351 | 시간 97[s] | 손실 3.51\n",
      "| 에폭 1 |  반복 341 / 351 | 시간 103[s] | 손실 3.46\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[91m☒\u001b[0m ----------\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[91m☒\u001b[0m ----------\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[91m☒\u001b[0m ----------\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[91m☒\u001b[0m ----------\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[91m☒\u001b[0m ----------\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[91m☒\u001b[0m ----------\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[91m☒\u001b[0m ----------\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[91m☒\u001b[0m ----------\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[91m☒\u001b[0m ----------\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[91m☒\u001b[0m ----------\n",
      "---\n",
      "val acc 0.000%\n",
      "| 에폭 2 |  반복 1 / 351 | 시간 0[s] | 손실 3.40\n",
      "| 에폭 2 |  반복 21 / 351 | 시간 6[s] | 손실 3.36\n",
      "| 에폭 2 |  반복 41 / 351 | 시간 12[s] | 손실 3.28\n",
      "| 에폭 2 |  반복 61 / 351 | 시간 18[s] | 손실 3.20\n",
      "| 에폭 2 |  반복 81 / 351 | 시간 25[s] | 손실 3.11\n",
      "| 에폭 2 |  반복 101 / 351 | 시간 31[s] | 손실 3.02\n",
      "| 에폭 2 |  반복 121 / 351 | 시간 37[s] | 손실 2.92\n",
      "| 에폭 2 |  반복 141 / 351 | 시간 43[s] | 손실 2.82\n",
      "| 에폭 2 |  반복 161 / 351 | 시간 49[s] | 손실 2.73\n",
      "| 에폭 2 |  반복 181 / 351 | 시간 55[s] | 손실 2.65\n",
      "| 에폭 2 |  반복 201 / 351 | 시간 61[s] | 손실 2.59\n",
      "| 에폭 2 |  반복 221 / 351 | 시간 67[s] | 손실 2.53\n",
      "| 에폭 2 |  반복 241 / 351 | 시간 73[s] | 손실 2.50\n",
      "| 에폭 2 |  반복 261 / 351 | 시간 79[s] | 손실 2.46\n",
      "| 에폭 2 |  반복 281 / 351 | 시간 85[s] | 손실 2.42\n",
      "| 에폭 2 |  반복 301 / 351 | 시간 91[s] | 손실 2.39\n",
      "| 에폭 2 |  반복 321 / 351 | 시간 97[s] | 손실 2.38\n",
      "| 에폭 2 |  반복 341 / 351 | 시간 102[s] | 손실 2.34\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[91m☒\u001b[0m 1---------\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[91m☒\u001b[0m 0---------\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[91m☒\u001b[0m 1---------\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[91m☒\u001b[0m 0---------\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[91m☒\u001b[0m 0---------\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[91m☒\u001b[0m 1---------\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[91m☒\u001b[0m 1---------\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[91m☒\u001b[0m 1---------\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[91m☒\u001b[0m 1---------\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[91m☒\u001b[0m 0---------\n",
      "---\n",
      "val acc 0.000%\n",
      "| 에폭 3 |  반복 1 / 351 | 시간 0[s] | 손실 2.34\n",
      "| 에폭 3 |  반복 21 / 351 | 시간 6[s] | 손실 2.32\n",
      "| 에폭 3 |  반복 41 / 351 | 시간 12[s] | 손실 2.30\n",
      "| 에폭 3 |  반복 61 / 351 | 시간 18[s] | 손실 2.28\n",
      "| 에폭 3 |  반복 81 / 351 | 시간 23[s] | 손실 2.27\n",
      "| 에폭 3 |  반복 101 / 351 | 시간 29[s] | 손실 2.26\n",
      "| 에폭 3 |  반복 121 / 351 | 시간 35[s] | 손실 2.24\n",
      "| 에폭 3 |  반복 141 / 351 | 시간 41[s] | 손실 2.23\n",
      "| 에폭 3 |  반복 161 / 351 | 시간 48[s] | 손실 2.22\n",
      "| 에폭 3 |  반복 181 / 351 | 시간 54[s] | 손실 2.21\n",
      "| 에폭 3 |  반복 201 / 351 | 시간 60[s] | 손실 2.20\n",
      "| 에폭 3 |  반복 221 / 351 | 시간 66[s] | 손실 2.19\n",
      "| 에폭 3 |  반복 241 / 351 | 시간 72[s] | 손실 2.19\n",
      "| 에폭 3 |  반복 261 / 351 | 시간 78[s] | 손실 2.18\n",
      "| 에폭 3 |  반복 281 / 351 | 시간 84[s] | 손실 2.17\n",
      "| 에폭 3 |  반복 301 / 351 | 시간 90[s] | 손실 2.16\n",
      "| 에폭 3 |  반복 321 / 351 | 시간 96[s] | 손실 2.16\n",
      "| 에폭 3 |  반복 341 / 351 | 시간 102[s] | 손실 2.15\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[91m☒\u001b[0m 10-0------\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[91m☒\u001b[0m 11--------\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[91m☒\u001b[0m 10-0------\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[91m☒\u001b[0m 11--------\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[91m☒\u001b[0m 11--------\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[91m☒\u001b[0m 11--------\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[91m☒\u001b[0m 10-0------\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[91m☒\u001b[0m 10-0------\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[91m☒\u001b[0m 10-0------\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[91m☒\u001b[0m 11--------\n",
      "---\n",
      "val acc 0.000%\n",
      "| 에폭 4 |  반복 1 / 351 | 시간 0[s] | 손실 2.14\n",
      "| 에폭 4 |  반복 21 / 351 | 시간 6[s] | 손실 2.14\n",
      "| 에폭 4 |  반복 41 / 351 | 시간 12[s] | 손실 2.13\n",
      "| 에폭 4 |  반복 61 / 351 | 시간 19[s] | 손실 2.14\n",
      "| 에폭 4 |  반복 81 / 351 | 시간 25[s] | 손실 2.12\n",
      "| 에폭 4 |  반복 101 / 351 | 시간 31[s] | 손실 2.12\n",
      "| 에폭 4 |  반복 121 / 351 | 시간 37[s] | 손실 2.12\n",
      "| 에폭 4 |  반복 141 / 351 | 시간 43[s] | 손실 2.11\n",
      "| 에폭 4 |  반복 161 / 351 | 시간 49[s] | 손실 2.10\n",
      "| 에폭 4 |  반복 181 / 351 | 시간 56[s] | 손실 2.10\n",
      "| 에폭 4 |  반복 201 / 351 | 시간 62[s] | 손실 2.10\n",
      "| 에폭 4 |  반복 221 / 351 | 시간 68[s] | 손실 2.10\n",
      "| 에폭 4 |  반복 241 / 351 | 시간 74[s] | 손실 2.09\n",
      "| 에폭 4 |  반복 261 / 351 | 시간 80[s] | 손실 2.08\n",
      "| 에폭 4 |  반복 281 / 351 | 시간 86[s] | 손실 2.08\n",
      "| 에폭 4 |  반복 301 / 351 | 시간 92[s] | 손실 2.08\n",
      "| 에폭 4 |  반복 321 / 351 | 시간 98[s] | 손실 2.07\n",
      "| 에폭 4 |  반복 341 / 351 | 시간 104[s] | 손실 2.07\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[91m☒\u001b[0m 110-0--0--\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[91m☒\u001b[0m 11-0------\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[91m☒\u001b[0m 11-0--0---\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[91m☒\u001b[0m 11-0------\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[91m☒\u001b[0m 11-0------\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[91m☒\u001b[0m 11-0--0---\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[91m☒\u001b[0m 110-0--0--\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[91m☒\u001b[0m 110-0--0--\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[91m☒\u001b[0m 110-0--0--\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[91m☒\u001b[0m 11-0------\n",
      "---\n",
      "val acc 0.000%\n",
      "| 에폭 5 |  반복 1 / 351 | 시간 0[s] | 손실 2.07\n",
      "| 에폭 5 |  반복 21 / 351 | 시간 6[s] | 손실 2.06\n",
      "| 에폭 5 |  반복 41 / 351 | 시간 12[s] | 손실 2.06\n",
      "| 에폭 5 |  반복 61 / 351 | 시간 18[s] | 손실 2.06\n",
      "| 에폭 5 |  반복 81 / 351 | 시간 24[s] | 손실 2.05\n",
      "| 에폭 5 |  반복 101 / 351 | 시간 30[s] | 손실 2.05\n",
      "| 에폭 5 |  반복 121 / 351 | 시간 36[s] | 손실 2.04\n",
      "| 에폭 5 |  반복 141 / 351 | 시간 42[s] | 손실 2.04\n",
      "| 에폭 5 |  반복 161 / 351 | 시간 48[s] | 손실 2.04\n",
      "| 에폭 5 |  반복 181 / 351 | 시간 54[s] | 손실 2.03\n",
      "| 에폭 5 |  반복 201 / 351 | 시간 61[s] | 손실 2.03\n",
      "| 에폭 5 |  반복 221 / 351 | 시간 67[s] | 손실 2.02\n",
      "| 에폭 5 |  반복 241 / 351 | 시간 73[s] | 손실 2.02\n",
      "| 에폭 5 |  반복 261 / 351 | 시간 79[s] | 손실 2.02\n",
      "| 에폭 5 |  반복 281 / 351 | 시간 85[s] | 손실 2.02\n",
      "| 에폭 5 |  반복 301 / 351 | 시간 91[s] | 손실 2.01\n",
      "| 에폭 5 |  반복 321 / 351 | 시간 97[s] | 손실 2.00\n",
      "| 에폭 5 |  반복 341 / 351 | 시간 103[s] | 손실 2.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[91m☒\u001b[0m 110-0-0-0-\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[91m☒\u001b[0m 11-0-0-0-0\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[91m☒\u001b[0m 110-0-0-0-\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[91m☒\u001b[0m 11-0-0-0-0\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[91m☒\u001b[0m 11-0-0-0-0\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[91m☒\u001b[0m 11-0-0-0-0\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[91m☒\u001b[0m 110-0-0-0-\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[91m☒\u001b[0m 110-0-0-0-\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[91m☒\u001b[0m 110-0-0-0-\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[91m☒\u001b[0m 11-0-0-0-0\n",
      "---\n",
      "val acc 0.000%\n",
      "| 에폭 6 |  반복 1 / 351 | 시간 0[s] | 손실 2.00\n",
      "| 에폭 6 |  반복 21 / 351 | 시간 6[s] | 손실 2.00\n",
      "| 에폭 6 |  반복 41 / 351 | 시간 12[s] | 손실 1.99\n",
      "| 에폭 6 |  반복 61 / 351 | 시간 18[s] | 손실 1.99\n",
      "| 에폭 6 |  반복 81 / 351 | 시간 24[s] | 손실 1.98\n",
      "| 에폭 6 |  반복 101 / 351 | 시간 31[s] | 손실 1.98\n",
      "| 에폭 6 |  반복 121 / 351 | 시간 37[s] | 손실 1.98\n",
      "| 에폭 6 |  반복 141 / 351 | 시간 43[s] | 손실 1.97\n",
      "| 에폭 6 |  반복 161 / 351 | 시간 50[s] | 손실 1.97\n",
      "| 에폭 6 |  반복 181 / 351 | 시간 55[s] | 손실 1.96\n",
      "| 에폭 6 |  반복 201 / 351 | 시간 62[s] | 손실 1.96\n",
      "| 에폭 6 |  반복 221 / 351 | 시간 68[s] | 손실 1.95\n",
      "| 에폭 6 |  반복 241 / 351 | 시간 73[s] | 손실 1.95\n",
      "| 에폭 6 |  반복 261 / 351 | 시간 80[s] | 손실 1.94\n",
      "| 에폭 6 |  반복 281 / 351 | 시간 86[s] | 손실 1.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 6 |  반복 301 / 351 | 시간 92[s] | 손실 1.93\n",
      "| 에폭 6 |  반복 321 / 351 | 시간 98[s] | 손실 1.93\n",
      "| 에폭 6 |  반복 341 / 351 | 시간 104[s] | 손실 1.92\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[91m☒\u001b[0m 19-0-0-0-0\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[91m☒\u001b[0m 19-0-0-0-0\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[91m☒\u001b[0m 19-0-0-0-0\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[91m☒\u001b[0m 19-0-0-0-0\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[91m☒\u001b[0m 19-0-0-0-0\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[91m☒\u001b[0m 19-0-0-0-0\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[91m☒\u001b[0m 19-0-0-0-0\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[91m☒\u001b[0m 19-0-0-0-0\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[91m☒\u001b[0m 19-0-0-0-0\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[91m☒\u001b[0m 19-0-0-0-0\n",
      "---\n",
      "val acc 0.000%\n",
      "| 에폭 7 |  반복 1 / 351 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 7 |  반복 21 / 351 | 시간 6[s] | 손실 1.91\n",
      "| 에폭 7 |  반복 41 / 351 | 시간 11[s] | 손실 1.91\n",
      "| 에폭 7 |  반복 61 / 351 | 시간 17[s] | 손실 1.91\n",
      "| 에폭 7 |  반복 81 / 351 | 시간 23[s] | 손실 1.90\n",
      "| 에폭 7 |  반복 101 / 351 | 시간 29[s] | 손실 1.90\n",
      "| 에폭 7 |  반복 121 / 351 | 시간 35[s] | 손실 1.89\n",
      "| 에폭 7 |  반복 141 / 351 | 시간 40[s] | 손실 1.88\n",
      "| 에폭 7 |  반복 161 / 351 | 시간 46[s] | 손실 1.88\n",
      "| 에폭 7 |  반복 181 / 351 | 시간 52[s] | 손실 1.88\n",
      "| 에폭 7 |  반복 201 / 351 | 시간 58[s] | 손실 1.87\n",
      "| 에폭 7 |  반복 221 / 351 | 시간 64[s] | 손실 1.86\n",
      "| 에폭 7 |  반복 241 / 351 | 시간 70[s] | 손실 1.85\n",
      "| 에폭 7 |  반복 261 / 351 | 시간 75[s] | 손실 1.85\n",
      "| 에폭 7 |  반복 281 / 351 | 시간 81[s] | 손실 1.85\n",
      "| 에폭 7 |  반복 301 / 351 | 시간 87[s] | 손실 1.84\n",
      "| 에폭 7 |  반복 321 / 351 | 시간 93[s] | 손실 1.83\n",
      "| 에폭 7 |  반복 341 / 351 | 시간 99[s] | 손실 1.83\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "val acc 0.000%\n",
      "| 에폭 8 |  반복 1 / 351 | 시간 0[s] | 손실 1.82\n",
      "| 에폭 8 |  반복 21 / 351 | 시간 6[s] | 손실 1.82\n",
      "| 에폭 8 |  반복 41 / 351 | 시간 11[s] | 손실 1.82\n",
      "| 에폭 8 |  반복 61 / 351 | 시간 17[s] | 손실 1.81\n",
      "| 에폭 8 |  반복 81 / 351 | 시간 23[s] | 손실 1.80\n",
      "| 에폭 8 |  반복 101 / 351 | 시간 29[s] | 손실 1.80\n",
      "| 에폭 8 |  반복 121 / 351 | 시간 34[s] | 손실 1.79\n",
      "| 에폭 8 |  반복 141 / 351 | 시간 40[s] | 손실 1.78\n",
      "| 에폭 8 |  반복 161 / 351 | 시간 46[s] | 손실 1.78\n",
      "| 에폭 8 |  반복 181 / 351 | 시간 52[s] | 손실 1.77\n",
      "| 에폭 8 |  반복 201 / 351 | 시간 58[s] | 손실 1.77\n",
      "| 에폭 8 |  반복 221 / 351 | 시간 63[s] | 손실 1.76\n",
      "| 에폭 8 |  반복 241 / 351 | 시간 69[s] | 손실 1.76\n",
      "| 에폭 8 |  반복 261 / 351 | 시간 75[s] | 손실 1.76\n",
      "| 에폭 8 |  반복 281 / 351 | 시간 81[s] | 손실 1.75\n",
      "| 에폭 8 |  반복 301 / 351 | 시간 87[s] | 손실 1.74\n",
      "| 에폭 8 |  반복 321 / 351 | 시간 92[s] | 손실 1.74\n",
      "| 에폭 8 |  반복 341 / 351 | 시간 98[s] | 손실 1.73\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "val acc 0.000%\n",
      "| 에폭 9 |  반복 1 / 351 | 시간 0[s] | 손실 1.71\n",
      "| 에폭 9 |  반복 21 / 351 | 시간 6[s] | 손실 1.72\n",
      "| 에폭 9 |  반복 41 / 351 | 시간 11[s] | 손실 1.71\n",
      "| 에폭 9 |  반복 61 / 351 | 시간 17[s] | 손실 1.71\n",
      "| 에폭 9 |  반복 81 / 351 | 시간 23[s] | 손실 1.71\n",
      "| 에폭 9 |  반복 101 / 351 | 시간 29[s] | 손실 1.70\n",
      "| 에폭 9 |  반복 121 / 351 | 시간 34[s] | 손실 1.69\n",
      "| 에폭 9 |  반복 141 / 351 | 시간 40[s] | 손실 1.69\n",
      "| 에폭 9 |  반복 161 / 351 | 시간 46[s] | 손실 1.68\n",
      "| 에폭 9 |  반복 181 / 351 | 시간 52[s] | 손실 1.68\n",
      "| 에폭 9 |  반복 201 / 351 | 시간 58[s] | 손실 1.67\n",
      "| 에폭 9 |  반복 221 / 351 | 시간 63[s] | 손실 1.67\n",
      "| 에폭 9 |  반복 241 / 351 | 시간 69[s] | 손실 1.66\n",
      "| 에폭 9 |  반복 261 / 351 | 시간 75[s] | 손실 1.66\n",
      "| 에폭 9 |  반복 281 / 351 | 시간 81[s] | 손실 1.66\n",
      "| 에폭 9 |  반복 301 / 351 | 시간 87[s] | 손실 1.65\n",
      "| 에폭 9 |  반복 321 / 351 | 시간 92[s] | 손실 1.64\n",
      "| 에폭 9 |  반복 341 / 351 | 시간 98[s] | 손실 1.64\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[91m☒\u001b[0m 199-0-0-0-\n",
      "---\n",
      "val acc 0.000%\n",
      "| 에폭 10 |  반복 1 / 351 | 시간 0[s] | 손실 1.64\n",
      "| 에폭 10 |  반복 21 / 351 | 시간 6[s] | 손실 1.63\n",
      "| 에폭 10 |  반복 41 / 351 | 시간 11[s] | 손실 1.62\n",
      "| 에폭 10 |  반복 61 / 351 | 시간 17[s] | 손실 1.62\n",
      "| 에폭 10 |  반복 81 / 351 | 시간 23[s] | 손실 1.62\n",
      "| 에폭 10 |  반복 101 / 351 | 시간 29[s] | 손실 1.61\n",
      "| 에폭 10 |  반복 121 / 351 | 시간 35[s] | 손실 1.61\n",
      "| 에폭 10 |  반복 141 / 351 | 시간 41[s] | 손실 1.60\n",
      "| 에폭 10 |  반복 161 / 351 | 시간 47[s] | 손실 1.60\n",
      "| 에폭 10 |  반복 181 / 351 | 시간 53[s] | 손실 1.59\n",
      "| 에폭 10 |  반복 201 / 351 | 시간 58[s] | 손실 1.59\n",
      "| 에폭 10 |  반복 221 / 351 | 시간 64[s] | 손실 1.58\n",
      "| 에폭 10 |  반복 241 / 351 | 시간 70[s] | 손실 1.59\n",
      "| 에폭 10 |  반복 261 / 351 | 시간 76[s] | 손실 1.58\n",
      "| 에폭 10 |  반복 281 / 351 | 시간 82[s] | 손실 1.57\n",
      "| 에폭 10 |  반복 301 / 351 | 시간 87[s] | 손실 1.56\n",
      "| 에폭 10 |  반복 321 / 351 | 시간 93[s] | 손실 1.57\n",
      "| 에폭 10 |  반복 341 / 351 | 시간 99[s] | 손실 1.56\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[91m☒\u001b[0m 199-0-0-01\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[91m☒\u001b[0m 199-0-0-01\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[91m☒\u001b[0m 199-0-0-01\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[91m☒\u001b[0m 199-0-0-01\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[91m☒\u001b[0m 199-0-0-01\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[91m☒\u001b[0m 199-0-0-01\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[91m☒\u001b[0m 199-0-0-01\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[91m☒\u001b[0m 199-0-0-01\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[91m☒\u001b[0m 199-0-0-01\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[91m☒\u001b[0m 199-0-0-01\n",
      "---\n",
      "val acc 0.000%\n"
     ]
    }
   ],
   "source": [
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('date.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# 입력 문장 반전\n",
    "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hidden_size = 256\n",
    "batch_size = 128\n",
    "max_epoch = 10\n",
    "max_grad = 5.0\n",
    "\n",
    "model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1, batch_size=batch_size, max_grad=max_grad)\n",
    "    \n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model, question, correct, id_to_char, verbose, is_reverse=True)\n",
    "        \n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list.append(acc)\n",
    "    print('val acc %.3f%%' % (acc * 100))\n",
    "    \n",
    "model.save_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 351 | 시간 0[s] | 손실 4.08\n",
      "| 에폭 1 |  반복 21 / 351 | 시간 6[s] | 손실 3.09\n",
      "| 에폭 1 |  반복 41 / 351 | 시간 12[s] | 손실 1.87\n",
      "| 에폭 1 |  반복 61 / 351 | 시간 18[s] | 손실 1.66\n",
      "| 에폭 1 |  반복 81 / 351 | 시간 24[s] | 손실 1.31\n",
      "| 에폭 1 |  반복 101 / 351 | 시간 30[s] | 손실 1.17\n",
      "| 에폭 1 |  반복 121 / 351 | 시간 36[s] | 손실 1.14\n",
      "| 에폭 1 |  반복 141 / 351 | 시간 42[s] | 손실 1.09\n",
      "| 에폭 1 |  반복 161 / 351 | 시간 48[s] | 손실 1.05\n",
      "| 에폭 1 |  반복 181 / 351 | 시간 55[s] | 손실 1.04\n",
      "| 에폭 1 |  반복 201 / 351 | 시간 61[s] | 손실 1.03\n",
      "| 에폭 1 |  반복 221 / 351 | 시간 67[s] | 손실 1.02\n",
      "| 에폭 1 |  반복 241 / 351 | 시간 73[s] | 손실 1.01\n",
      "| 에폭 1 |  반복 261 / 351 | 시간 79[s] | 손실 1.01\n",
      "| 에폭 1 |  반복 281 / 351 | 시간 85[s] | 손실 1.00\n",
      "| 에폭 1 |  반복 301 / 351 | 시간 91[s] | 손실 1.00\n",
      "| 에폭 1 |  반복 321 / 351 | 시간 97[s] | 손실 1.00\n",
      "| 에폭 1 |  반복 341 / 351 | 시간 103[s] | 손실 0.99\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[91m☒\u001b[0m 1992-03-11\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[91m☒\u001b[0m 1992-03-11\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[91m☒\u001b[0m 1992-03-11\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[91m☒\u001b[0m 1992-03-11\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[91m☒\u001b[0m 1992-03-11\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[91m☒\u001b[0m 1992-03-11\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[91m☒\u001b[0m 1992-03-11\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[91m☒\u001b[0m 1992-03-11\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[91m☒\u001b[0m 1992-03-11\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[91m☒\u001b[0m 1992-03-11\n",
      "---\n",
      "val acc 0.000%\n",
      "| 에폭 2 |  반복 1 / 351 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 21 / 351 | 시간 6[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 41 / 351 | 시간 12[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 61 / 351 | 시간 18[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 81 / 351 | 시간 25[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 101 / 351 | 시간 31[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 121 / 351 | 시간 37[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 141 / 351 | 시간 43[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 161 / 351 | 시간 49[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 181 / 351 | 시간 55[s] | 손실 0.98\n",
      "| 에폭 2 |  반복 201 / 351 | 시간 61[s] | 손실 0.98\n",
      "| 에폭 2 |  반복 221 / 351 | 시간 67[s] | 손실 0.96\n",
      "| 에폭 2 |  반복 241 / 351 | 시간 73[s] | 손실 0.94\n",
      "| 에폭 2 |  반복 261 / 351 | 시간 79[s] | 손실 0.91\n",
      "| 에폭 2 |  반복 281 / 351 | 시간 85[s] | 손실 0.87\n",
      "| 에폭 2 |  반복 301 / 351 | 시간 91[s] | 손실 0.81\n",
      "| 에폭 2 |  반복 321 / 351 | 시간 97[s] | 손실 0.76\n",
      "| 에폭 2 |  반복 341 / 351 | 시간 103[s] | 손실 0.68\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[91m☒\u001b[0m 1994-08-14\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[91m☒\u001b[0m 2001-11-14\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[91m☒\u001b[0m 2003-09-28\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[91m☒\u001b[0m 2011-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[91m☒\u001b[0m 1992-10-08\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[91m☒\u001b[0m 2003-08-28\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[91m☒\u001b[0m 2007-04-04\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[91m☒\u001b[0m 1993-08-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[91m☒\u001b[0m 2011-11-24\n",
      "---\n",
      "val acc 0.000%\n",
      "| 에폭 3 |  반복 1 / 351 | 시간 0[s] | 손실 0.60\n",
      "| 에폭 3 |  반복 21 / 351 | 시간 6[s] | 손실 0.54\n",
      "| 에폭 3 |  반복 41 / 351 | 시간 11[s] | 손실 0.43\n",
      "| 에폭 3 |  반복 61 / 351 | 시간 17[s] | 손실 0.33\n",
      "| 에폭 3 |  반복 81 / 351 | 시간 23[s] | 손실 0.24\n",
      "| 에폭 3 |  반복 101 / 351 | 시간 29[s] | 손실 0.17\n",
      "| 에폭 3 |  반복 121 / 351 | 시간 34[s] | 손실 0.11\n",
      "| 에폭 3 |  반복 141 / 351 | 시간 40[s] | 손실 0.08\n",
      "| 에폭 3 |  반복 161 / 351 | 시간 46[s] | 손실 0.06\n",
      "| 에폭 3 |  반복 181 / 351 | 시간 52[s] | 손실 0.05\n",
      "| 에폭 3 |  반복 201 / 351 | 시간 58[s] | 손실 0.04\n",
      "| 에폭 3 |  반복 221 / 351 | 시간 63[s] | 손실 0.03\n",
      "| 에폭 3 |  반복 241 / 351 | 시간 69[s] | 손실 0.03\n",
      "| 에폭 3 |  반복 261 / 351 | 시간 75[s] | 손실 0.02\n",
      "| 에폭 3 |  반복 281 / 351 | 시간 81[s] | 손실 0.02\n",
      "| 에폭 3 |  반복 301 / 351 | 시간 87[s] | 손실 0.01\n",
      "| 에폭 3 |  반복 321 / 351 | 시간 92[s] | 손실 0.01\n",
      "| 에폭 3 |  반복 341 / 351 | 시간 98[s] | 손실 0.01\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[92m☑\u001b[0m 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[92m☑\u001b[0m 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[92m☑\u001b[0m 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[92m☑\u001b[0m 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[92m☑\u001b[0m 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[92m☑\u001b[0m 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[92m☑\u001b[0m 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[92m☑\u001b[0m 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[92m☑\u001b[0m 2016-11-06\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "acc_list1 = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1, batch_size=batch_size, max_grad=max_grad)\n",
    "    \n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model, question, correct, id_to_char, verbose, is_reverse=True)\n",
    "        \n",
    "    acc1 = float(correct_num) / len(x_test)\n",
    "    acc_list1.append(acc1)\n",
    "    print('val acc %.3f%%' % (acc * 100))\n",
    "    \n",
    "model.save_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='v')\n",
    "plt.plot(x, acc_list1, marker='o')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_8-26.png\" width=600>\n",
    "\n",
    "* 기본 seq2seq : 낮은 정확도\n",
    "* peeky와 어텐션 : 비슷한 정확도, 어텐션이 학습 속도우세\n",
    "* 현실의 시계열은 훨씬 복잡 : 어텐션 추천\n",
    "* 어텐션 쓰더라도 SGD쓰면 최악의 결과가 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어텐션 시각화\n",
    "* Time Attention 계층의 인스턴스 변수 attention_weight에 각 시각의 어텐션 가중치를 이용\n",
    "    * 입력 문장과 출력 문장의 단어 대응 관계를 2차원 맵으로 그릴 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from dataset import sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from attention_seq2seq import AttentionSeq2seq\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    sequence.load_data('date.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# 입력 문장 반전\n",
    "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hidden_size = 256\n",
    "\n",
    "model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "model.load_params()\n",
    "\n",
    "_idx = 0\n",
    "def visualize(attention_map, row_labels, column_labels):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pcolor(attention_map, cmap=plt.cm.Greys_r, vmin=0.0, vmax=1.0)\n",
    "\n",
    "    ax.patch.set_facecolor('black')\n",
    "    ax.set_yticks(np.arange(attention_map.shape[0])+0.5, minor=False)\n",
    "    ax.set_xticks(np.arange(attention_map.shape[1])+0.5, minor=False)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xticklabels(row_labels, minor=False)\n",
    "    ax.set_yticklabels(column_labels, minor=False)\n",
    "\n",
    "    global _idx\n",
    "    _idx += 1\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "np.random.seed(1984)\n",
    "for _ in range(5):\n",
    "    idx = [np.random.randint(0, len(x_test))]\n",
    "    x = x_test[idx]\n",
    "    t = t_test[idx]\n",
    "\n",
    "    model.forward(x, t)\n",
    "    d = model.decoder.attention.attention_weights\n",
    "    d = np.array(d)\n",
    "    attention_map = d.reshape(d.shape[0], d.shape[2])\n",
    "\n",
    "    # 출력하기 위해 반전\n",
    "    attention_map = attention_map[:,::-1]\n",
    "    x = x[:,::-1]\n",
    "\n",
    "    row_labels = [id_to_char[i] for i in x[0]]\n",
    "    column_labels = [id_to_char[i] for i in t[0]]\n",
    "    column_labels = column_labels[1:]\n",
    "\n",
    "    visualize(attention_map, row_labels, column_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 어텐션에 관한 남은 이야기\n",
    "### 양방향 RNN\n",
    "* 양방향 LSTM에 역방향도 처리하는 LSTM 계층을 추가\n",
    "    * 각 시각마다 두 LSTM 계층의 은닉 상태를 연결시킨 벡터를 최종 은닉 상태로 처리\n",
    "    * 서로 합하거나 평균하는 방법도 있다.\n",
    "\n",
    "* 이점 : 은닉 상태 벡터에 좌, 우 양쪽 방향의 균형 잡힌 정보를 인코딩 가능\n",
    "* 구현 : 단순히 입력 단어를 반대로 나열해서 입력하는 LSTM 계층을 하나 더 만든 후, 정방향으로 처리하는 계층의 출력과 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeBiLSTM:\n",
    "    def __init__(self, Wx1, Wh1, b1,\n",
    "                 Wx2, Wh2, b2, stateful=False):\n",
    "        self.forward_lstm = TimeLSTM(Wx1, Wh1, b1, stateful)\n",
    "        self.backward_lstm = TimeLSTM(Wx2, Wh2, b2, stateful)\n",
    "        self.params = self.forward_lstm.params + self.backward_lstm.params\n",
    "        self.grads = self.forward_lstm.grads + self.backward_lstm.grads\n",
    "\n",
    "    def forward(self, xs):\n",
    "        o1 = self.forward_lstm.forward(xs)\n",
    "        o2 = self.backward_lstm.forward(xs[:, ::-1])\n",
    "        o2 = o2[:, ::-1]\n",
    "\n",
    "        out = np.concatenate((o1, o2), axis=2)\n",
    "        return out\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        H = dhs.shape[2] // 2\n",
    "        do1 = dhs[:, :, :H]\n",
    "        do2 = dhs[:, :, H:]\n",
    "\n",
    "        dxs1 = self.forward_lstm.backward(do1)\n",
    "        do2 = do2[:, ::-1]\n",
    "        dxs2 = self.backward_lstm.backward(do2)\n",
    "        dxs2 = dxs2[:, ::-1]\n",
    "        dxs = dxs1 + dxs2\n",
    "        return dxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어텐션 계층 사용 방법\n",
    "<img src=\"./images/fig_8-32.png\" width=700>\n",
    "\n",
    "* Attention 계층의 출력이 다음 시각의 LSTM 계층에 입력되도록 연결\n",
    "* 직접 구현한 경우는 Affine 계층에서 맥락 벡터를 이용한 반면 이 경우에는 LSTM 계층에서 맥락 벡터를 이용\n",
    "\n",
    "* 구현 측면\n",
    "    * LSTM과 Affine 계층 사이에 Attention 계층을 삽입하는 것이 쉽다.\n",
    "    * 최종 정확도 : 큰 차이가 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seq2seq 심층화와 skip 연결\n",
    "<img src=\"./images/fig_8-33.png\" width=700>\n",
    "\n",
    "* 일반적으로 Encoder과 Decoder의 LSTM 계층을 동일한 수로 구성\n",
    "* 여러 방식으로 심층화 가능\n",
    "\n",
    "<img src=\"./images/fig_8-34.png\" width=300>\n",
    "\n",
    "* **skip 연결** : 층을 깊게 할 때 기울기가 잘 흐를 수 있도록 하는 방법\n",
    "    * 계층을 건너뛰는 연결\n",
    "    * LSTM의 출력과 LSTM을 통과하지 않은 출력의 잔차의 원소별 덧셈을 해준다.\n",
    "    * 덧셈은 역전파 시 기울기를 그대로 흘려보낼 수 있게 해준다.\n",
    "\n",
    "* 층을 깊게 하면 여전히 오버피팅 문제가 발생 가능\n",
    "    * 일반화 성능을 유지해주기 위해서 드롭아웃과 가중치 공유 등의 기술을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 어텐션 응용\n",
    "### 구글 신경망 기계 번역(GNMT)\n",
    "<img src=\"./images/fig_8-35.png\" width=700>\n",
    "\n",
    "### 트렌스포머\n",
    "* 트랜스포머 : RNN 대신 어텐션을 사용\n",
    "<img src=\"./images/fig_8-37.png\" width=600>\n",
    "<img src=\"./images/fig_8-38.png\" width=600>\n",
    "\n",
    "### 뉴럴튜닝머신(NMT)\n",
    "<img src=\"./images/fig_8-41.png\" width=700>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
