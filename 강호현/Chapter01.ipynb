{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1. 신경망복습\n",
    "## 수학과 파이썬 복습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 벡터와 행렬\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([1,2,3])\n",
    "x.__class__ # 클래스 이름 표기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim #1차원 배열이고 원소 수 3개인 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  3,  5],\n",
       "       [ 7,  9, 11]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#행렬의 원소별(element-wise) 연산\n",
    "W = np.array([[1,2,3],[4,5,6]])\n",
    "X = np.array([[0,1,2],[3,4,5]])\n",
    "W+X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2,  6],\n",
       "       [12, 20, 30]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 20],\n",
       "       [30, 40]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 브로드캐스트\n",
    "A = np.array([[1,2],[3,4]])\n",
    "A*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 40],\n",
       "       [30, 80]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([10,20])\n",
    "A*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 벡터의 내적과 행렬의 곱\n",
    "#벡터의 내적\n",
    "a = np.array([1,2,3])\n",
    "b = np.array([4,5,6])\n",
    "np.dot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 22],\n",
       "       [43, 50]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#행렬의 곱\n",
    "A = np.array([[1,2],[3,4]])\n",
    "B = np.array([[5,6],[7,8]])\n",
    "np.matmul(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 물론 둘다 np.dot() 가능하나 코드 상 분리해주어 의도를 명확히 하라!\n",
    "* 행렬 형상 확인도 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망의 추론\n",
    "### 신경망 추론 전체 그림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완전연결계층에 의한 변환 미니배치 버전\n",
    "import numpy as np\n",
    "W1 = np.random.randn(2,4) #가중치\n",
    "b1 = np.random.randn(4) # 편향\n",
    "x = np.random.randn(10,2) # 입력\n",
    "h = np.matmul(x, W1) + b1\n",
    "# 이를 비선형 효과 부여하는 것이 시그모이드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sigmoid(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망의 추론 정리\n",
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "x = np.random.randn(10,2)\n",
    "W1 = np.random.randn(2,4)\n",
    "b1 = np.random.randn(4)\n",
    "W2 = np.random.randn(4,3)\n",
    "b2 = np.random.randn(3)\n",
    "\n",
    "h = np.matmul(x, W1) + b1\n",
    "a = sigmoid(h)\n",
    "s = np.matmul(a, W2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.22070427  0.32307613 -1.20986535]\n",
      " [ 0.52263912 -0.15912166 -0.68624819]\n",
      " [ 0.59003801  0.05614804 -0.83803558]\n",
      " [ 0.14413684  0.54482023 -1.3760161 ]\n",
      " [ 0.52064946 -0.40946672 -0.58298002]\n",
      " [ 0.25810473  0.60267809 -1.32834165]\n",
      " [ 0.10706905  0.70880746 -1.40915585]\n",
      " [ 0.54234954 -0.05454548 -0.75123151]\n",
      " [ 0.30853025  0.12010321 -1.00253962]\n",
      " [ 0.5450725  -0.32357665 -0.60411009]]\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#계층 클래스화 및 순전파 구현\n",
    "#sigmoid\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.params = [] #학습할 매개변수 없으니 빈 것이다.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return 1 / (1+np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        W, b = self.params\n",
    "        out = np.matmul(x, W) + b\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        I, H, O = input_size, hidden_size, output_size\n",
    "        \n",
    "        # 가중치와 편향 초기화\n",
    "        W1 = np.random.randn(I, H)\n",
    "        b1 = np.random.randn(H)\n",
    "        W2 = np.random.randn(H, O)\n",
    "        b2 = np.random.randn(O)\n",
    "        \n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            Affine(W1, b1),\n",
    "            Sigmoid(),\n",
    "            Affine(W2, b2)\n",
    "        ]\n",
    "        \n",
    "        # 모든 가중치를 리스트에 모은다.\n",
    "        self.params = []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'C', 'D']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['A', 'B']\n",
    "a += ['C', 'D']\n",
    "a# 파이썬에서 리스트 결합방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10,2)\n",
    "model = TwoLayerNet(2,4,3)\n",
    "s = model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망의 학습\n",
    "### 손실 함수\n",
    "* 다중 클래스 분류 : 교차 엔트로피 오차\n",
    "### 미분과 기울기\n",
    "### 연쇄 법칙\n",
    "### 계산 그래프\n",
    "* 덧셈 노드\n",
    "* 곱셈 노드\n",
    "* 분기 노드\n",
    "* Repeat 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "D, N = 8,7\n",
    "x = np.random.randn(1, 0)\n",
    "y = np.repeat(x, N, axis=0)\n",
    "dy = np.random.randn(N, D) # 무작위 기울기\n",
    "dx = np.sum(dy, axis = 0, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum 노드\n",
    "import numpy as np\n",
    "D, N = 8,7\n",
    "x = np.random.randn(N, D) # 입력\n",
    "y = np.sum(x, axis = 0, keepdims= True)\n",
    "\n",
    "dy = np.random.randn(1, D)\n",
    "dx = np.repeat(dy, N, axis=0) # 역전파 기울기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum 노드의 순전파 = Repeat 노드의 역전파  \n",
    "Sum 노드의 역전파 = Repeat 노드의 순전파"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MatMul 노드\n",
    "class MatMul:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.x = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        W, = self.params #???\n",
    "        out = np.matmul(x, W)\n",
    "        self.x = x\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        W, = self.params\n",
    "        dx = np.matmul(dout, W.T)\n",
    "        dW = np.matmul(self.x.T, dout)\n",
    "        self.grads[0][...] = dW #[...]으로 생략 기호를 활용하면, 넘파이 뱅려이 가리키는 메모리 위치를 고정시킨 후 그 위치에 원소를 덮는다.\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigmoid 계층\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [],[]\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = 1 / (1+ np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - xelf.out) * self.out\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affine\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W,b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        W, b = self.params\n",
    "        out = np.matmul(x, W) + b\n",
    "        self.x = x\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        W, b = self.params\n",
    "        dx = np.matmul(dout, W.T)\n",
    "        dW = np.matmul(self.x.T, dout)\n",
    "        db = np.sum(dout, axis = 0)\n",
    "        \n",
    "        self.grads[0][...] = dW\n",
    "        self.grads[1][...] = db\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 갱신\n",
    "# 미니배치, 기울기 계산, 매개변수 갱신, 반복\n",
    "\n",
    "class SGD:\n",
    "    def __init__(self, lr=0.01): #초기화 학습률\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, params, grads): #매개변수 갱신\n",
    "        for i in range(len(params)):\n",
    "            params[i] -= self.lr * grads[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    model = TwoLayerNet(...)\n",
    "    optimizer = SGD()\n",
    "\n",
    "    for i in range(10000):\n",
    "        ...\n",
    "        x_batch, t_batch = get_mini_batch(...) #미니배치 획득\n",
    "        loss = model.forward(x_batch, t_batch)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망으로 문제를 풀다\n",
    "### 스파이럴 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (300, 2)\n",
      "t (300, 3)\n"
     ]
    }
   ],
   "source": [
    "#스파이럴 데이터셋\n",
    "import sys\n",
    "sys.path.append('..') #부모 디렉터리 파일 가져오도록 설정\n",
    "from dataset import spiral\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x, t = spiral.load_data()\n",
    "print('x', x.shape)\n",
    "print('t', t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 구현\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.layers import Affine, Sigmoid, SoftmaxWithLoss\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        I, H, O = input_size, hidden_size, output_size\n",
    "        \n",
    "        # 가중치와 편향 초기화\n",
    "        W1 = 0.01 * np.random.randn(I, H)\n",
    "        b1 = np.zeros(H)\n",
    "        W2 = 0.01 * np.random.randn(H, O)\n",
    "        b2 = np.zeros(O)\n",
    "        \n",
    "        #계층 생성\n",
    "        self.layers = [\n",
    "            Affine(W1, b1),\n",
    "            Sigmoid(),\n",
    "            Affine(W2, b2)\n",
    "        ]\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "        \n",
    "        # 가중치, 기울기를 리스트에 모으기\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict 메서드\n",
    "def predict(self, x):\n",
    "    for layer in self.layers:\n",
    "        x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "def forward(self, x, t):\n",
    "    score = self.predict(x)\n",
    "    loss = self.loss_layer.forward(Score, t)\n",
    "    return loss\n",
    "\n",
    "def backward(self, dout=1):\n",
    "    dout = self.loss_layer.backward(dout)\n",
    "    for layer in reversed(Self.layers):\n",
    "        dout = layer.backward(dout)\n",
    "    return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 코드\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
