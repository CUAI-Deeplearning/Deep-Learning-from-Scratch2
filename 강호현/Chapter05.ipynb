{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 순환 신경망(RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 확률과 언어 모델\n",
    "word2vec 복습 및 자연어 현상을 확률로 기술하고, 언어 모델 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec을 확률 관점에서 바라보다.\n",
    "* word2vec CBOW 모델 복습  \n",
    "* CBOW 모델  \n",
    "* $w_1, w_2, ..., w_T$ 단어열 말뭉치 고려\n",
    "* 타깃 : t번째 단어\n",
    "* 맥락 : 전후 (t-1, t+1)번째 단어\n",
    "![img](./images/fig_5-1.png)\n",
    "\n",
    " $w_{t-1}, w_{t+1}$이 주어질 때, 타깃 $w_t$가 될 확률\n",
    " $$P(w_t | w_{t-1}, w_{t+1})$$\n",
    " \n",
    " * 왼쪽 윈도우 맥락 한정\n",
    "![img](./images/fig_5-2.png)\n",
    "\n",
    "CBOW 확률\n",
    " $$P(w_t | w_{t-2}, w_{t-1})$$\n",
    " \n",
    " 이 표기에서 CBOW 손실 함수는 교차 엔트로피 오차로 유도한 결과로 나타낸다.\n",
    " $$L = -\\log{P(w_t | w_{t-2}, w_{t-1})}$$\n",
    " \n",
    " * CBOW 모델 학습 : 위의 손실 함수(말뭉치 전체의 손실 함수의 총합)을 최소화하는 가중치 매개변수 찾기  \n",
    "     * 맥락으로부터 타깃을 더 정확하게 추측 가능\n",
    "     \n",
    " 단어의 의미가 인코딩된 '단어의 분산 표현' 얻을 수 있다.  \n",
    " \n",
    " * 맥락으로부터 타깃을 추측하는 것 : $P(w_t | w_{t-2}, w_{t-1})$ 쓰임\n",
    "     * 언어 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 언어 모델\n",
    "* 언어 모델(Language Model) : 단어 나열에 확률 부여\n",
    "* 특정 단어 시퀸스에서 그 시퀸스가 일어날 가능성(혹은 자연스러운 단어 순서)를 확률로 평가\n",
    "    * \"you say good die\"는 낮은 확률 출력\n",
    "    \n",
    "* 다양한 응용 가능 : 기계 번역, 음성 인식  \n",
    "    * 음성 인식 : 후보 문장 생성 -> 언어 모델 -> _후보 문장이 문장으로써 자연스러운지_ 기준으로 순서  \n",
    "    * 새로운 문장 생성 : 단어 순서의 자연스러움을 확률적 평가 가능 -> 확률 분포에 따라 다음 적합한 단어를 자아낼 수 있음\n",
    "\n",
    "* 언어 모델 수식으로 설명  \n",
    "    * $w_1, .., w_m$ 출현할 확률을 $P(w_1, ...,w_m)$ : 동시 확률  \n",
    "    * 이를 사후 확률로 분해 가능하다.  \n",
    "$$P(w_1, ...,w_m) = P(w_m | w_1, ...,w_{m-1})P(w_{m-1} | w_1, ..., W_{m-2})\\\\ ... P(w_3|w_1, w_2) P(w_2 | w_1) P(w_1) \\\\ = \\prod_{t=1}^m P(w_t|w_1,...w_{t-1}) $$\n",
    "\n",
    "    * 동시확률은 사후 확률의 곱으로 나타낸다.\n",
    "    * 확률의 **곱셈정리**로 유도 가능\n",
    "    \n",
    "    $$P(A, B) = P(A|B)P(B)$$\n",
    "    A와 B가 모두 일어날 확률은 B가 일어날 확률과 B가 일어난 후 A가 일어날 확률을 곱한 값과 같다.\n",
    "    이로써 m개 동시 확률을 사후 확률로 나타낸다.\n",
    "    ![img](./images/e_5-6.png)\n",
    "    ![img](./images/e_5-7.png)\n",
    "\n",
    "이를 반복하면, 동시 확률이 사후 확률의 총곱으로 대표할 수 있다. (단, _사후 확률은 타깃 단어보다 왼쪽에 있는 모든 단어를 맥락으로 했을 때 확률이다._)\n",
    "\n",
    "![img](./images/fig_5-3.png)\n",
    "\n",
    "* 조건부 언어 모델(conditional language model) = 언어 모델\n",
    "$$P(w_t|w_1,...,w_{t-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW 모델을 언어 모델로?\n",
    "CBOW 모델을 언어 모델에 적용하는 방법  \n",
    "맥락의 크기를 특정 값으로 한정하여 근사적으로 표현  \n",
    "$$P(w_1,...,w_t) = \\prod_{t=1}^m P(w_1|w_1,...,w_{t-1}) \\approx \\prod_{t=1}^m P(w_t|w_{t-2}, w_{t-1})$$\n",
    "\n",
    "* 마르코프 연쇄 혹은 마르코프 모델\n",
    "    * 미래의 상태가 현재 상태에만 의존해 결정\n",
    "    * 사상의 확률이 그 직전 N개의 시간에만 의존 : N층 마르코프 연쇄\n",
    "    * 직전 2개의 단어만 의존해 다음 단어 정해지는 모델 : 2층 마르코프 연쇄\n",
    "    \n",
    "* 맥락의 크기는 임의 설정 가능하지만, 결국 특정 길이로 고정  \n",
    "* 맥락보다 더 왼쪽에 있는 단어의 정보가 무시\n",
    "\n",
    "![img](./images/fig_5-4.png)\n",
    "18번째 앞에 있는 Tom 기억하는 과제 : 맥락이 10개까지이면 제대로 답할 수 없다.  \n",
    "* 맥락을 키울 수 있지만,  CBOW 맥락 안의 단어 순서가 무시되는 한계 존재  \n",
    "* CBOW(Continuous bag of words) : 가방 안의 단어, 가방 속의 단어 순서는 무시된다.(=순서 대신 분포 이용)\n",
    "* CBOW에서 단어 순서 무시되는 사례\n",
    "![img](./images/fig_5-5.png)\n",
    "\n",
    "* 왼쪽 그림 : 은닉층에서 단어 벡터가 더해지므로 맥락 단어 순서 무시\n",
    "* you, say와 say, you 맥락 동일 취급\n",
    "\n",
    "* 맥락의 단어 순서 고려한 모델\n",
    "    * 오른쪽 그림 : 맥락의 단어 벡터를 은닉층에서 연결하는 방식\n",
    "    * 신경 확률론적 언어 모델(Neural Probabilistic Language Model)\n",
    "    * 한계 : 맥락에 비례해 가중치 매개변수 증가\n",
    "    \n",
    "* 해결 : 순환 신경망, RNN\n",
    "    * 맥락이 아무리 길어도 그 맥락의 정보를 기억 메커니즘\n",
    "    * 긴 시계열 데이터 대응 가능\n",
    "\n",
    "* word2vec : 단어의 분산 표현 얻을 목적을 고안됨. 언어 모델로는 잘 사용 안한다.  \n",
    "* 최근 단어의 분산 표현의 '질' 개선을 위해 RNN 언어 모델에서 word2vec 제안"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN이란\n",
    "Recurrent 라틴어 : 몇 번이나 반복해서 일어나는 일\n",
    "- 재발한다. 순환한다.  \n",
    "- 순환하는 신경망  \n",
    "\n",
    "* Recursive Neural Network : 재귀 신경망\n",
    "    * 트리 구조 데이터 처리하기 위한 신경망으로 순환 신경망과 다르다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순환하는 신경망\n",
    "* 순환한다 = 반복해서 되돌아감\n",
    "* 순환 : 시간을 지나 다시 원래 장소로 돌아온다. 그 과정을 반복한다.  \n",
    "* 순환하기 위해 **닫힌 경로** 필요\n",
    "    * 닫힌 경로, 순환하는 경로 존재해야 반복 왕래 가능\n",
    "    * 정보가 끊임없이 갱신\n",
    "\n",
    "* RNN 특징 : 순환하는 경로(닫힌 경로) 존재\n",
    "이를 따라 데이터가 끊임없이 순환. 데이터가 순환되므로 과거 정보 기억 + 최신 데이터 갱신 가능  \n",
    "\n",
    "* RNN 계층 : RNN에 이용되는 계층\n",
    "![img](./images/fig_5-6.png)\n",
    "\n",
    "순환하는 경로 포함 및 순환 경로를 따라 데이터 계층 안에서 순환 가능  \n",
    "$x_t$ 입력, t는 시각  \n",
    "시계열 데이터$(x_1, x_2, ..., x_t, ...)$가 RNN 계층에 입력  \n",
    "그 입력에 대응하여 $(h_0, h_1, ..., h_t, ... )$ 출력 \n",
    "* 각 시각에 입력된 $x_t$ 벡터 가정 : 문장(단어 순서) 다루는 경우\n",
    "    * 각 단어의 분산 표현(단어 벡터)가 $x_t$가 되고, 분산 표현이 순서대로 하나씩 RNN 계층 입력\n",
    "    \n",
    "* 90도 회전\n",
    "![img](./images/fig_5-7.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순환 구조 펼치기\n",
    "RNN 계층의 순환 구조  \n",
    "신경망 존재 없던 구조 : 펼치면 친숙한 신경망 변신\n",
    "![img](./images/fig_5-8.png)\n",
    "\n",
    "펼쳐서 오른쪽으로 성장하는 긴 신경망 변신 가능 : 피드포워드 신경망 같은 구조\n",
    "단, RNN 계층 모두가 실제로 같은 계층인 점이 다름\n",
    "\n",
    "* 시계열 데이터 인덱스는 시각 용어 사용\n",
    "\n",
    "각 시각의 RNN 계층 : 입력과 1개 전의 RNN 계층에서 출력  \n",
    "두 정보 바탕 현 시각의 출력 계산\n",
    "$$\\mathbf{h_t} = \\tanh(\\mathbf{h_{t-1}}\\mathbf{W_h} + \\mathbf{x_t}\\mathbf{ W_x} + \\mathbf{b})$$\n",
    "\n",
    "RNN의 $\\mathbf{h}$ : 상태를 기억해 시각이 1 단위 진행될 때마다 위의 형태로 갱신  \n",
    "그래서 출력 $\\mathbf{h_t}$ : 은닉 상태 hidden state 혹은 은닉 상태 벡터 hidden state vector로 부른다.\n",
    "\n",
    "![img](./images/fig_5-9.png)\n",
    "오른쪽 그림처럼 하나의 출력이 분기함을 기억하라!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPTT\n",
    "RNN 계층도 신경망과 같은 순서로 진행 가능\n",
    "![img](./images/fig_5-10.png)\n",
    "\n",
    "* 시간 방향으로 펼친 신경망의 오차역전파법 : BPTT(BackPropagation Through Time)\n",
    "    * 학습이 가능하지만 문제는 긴 시계열 데이터 학습시 발생\n",
    "    * 시간 크기가 커지는 것에 비례하여 BPTT 자원도 증가하며, 역전파 시 기울기도 불안정해짐\n",
    "    * 매 시각 RNN 계층의 중간 데이터를 메모리 유지해야 한다.\n",
    "        * 시계열 데이터가 길어짐에 따라 계산량 및 메모리 량 증가\n",
    "        \n",
    "### Truncated BPTT\n",
    "큰 시계열 데이터는 신경망 연결을 적당한 길이로 끊는다.\n",
    "너무 길어진 신경망을 적당한 지점에서 잘라내어 작은 신경망 여러 개로 만든다  \n",
    "잘라낸 작은 신경망에서 오차역전파법 수행\n",
    "\n",
    "* Truncated 잘린  \n",
    "\n",
    "* 순전파의 흐름은 끊어지지 않고 전파하고, 역전파의 연결만 끊는다.\n",
    "\n",
    "* 너무 긴 시계열은 기울기 소실, 메모리와 계산량 문제 발생\n",
    "![img](./images/fig_5-11.png)\n",
    "* 역전파 연결되는 RNN 계층을 블록  \n",
    "* 순전파는 끊어서는 안된다. 데이터를 순서대로sequential) 입력해야 한다.  \n",
    "신경망은 미니배치 학습시 데이터를 무작위 선택해서 입력했지만, RNN은 다르다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](./images/fig_5-12.png)\n",
    "* 첫 번째 블록 입력 데이터를 RNN 계층에 제공\n",
    "* 순전파 수행 후 역전파 수행 : 원하는 기울기를 구할 수 있다.  \n",
    "\n",
    "![img](./images/fig_5-13.png)\n",
    "* 이어서 다음 블록의 입력 데이터를 입력해 오차역전파법 수행\n",
    "* 순전파 수행 후 역전파 수행\n",
    "* 이번 순전파 계산 시 앞 블록의 마지막 은닉 상태 $\\mathbf{h_9}$ 필요 : 순전파 계속 연결 가능\n",
    "* 이어서 3번째 블록 학습 시에도, 두 번째 블록의 마지막 은닉 상태인 $h_19$를 이용한다. \n",
    "* 순서대로 데이터 입력하고 은닉 상태를 계승하며 학습 수행\n",
    "\n",
    "![img](./images/fig_5-14.png)\n",
    "\n",
    "* 데이터를 순서대로 입력해 학습\n",
    "* 순전파 연결 유지하면서 블록 단위로 오차역전파법 적용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncated BPTT의 미니배치 학습\n",
    "지금까지는 미니배치 수가 1일 때 해당한다. 미니배치 학습을 수행하려면, 구체적인 배치 방식을 고려해 다음과 같이 데이터를 순서대로 입력해야 한다.  \n",
    "데이터 입력하는 시작 위치를 각 미니배치 시작 위치로 **옮겨줘야** 한다.  \n",
    "\n",
    "* 첫 번째 미니배치 때는 처음부터 순서대로 데이터 제공\n",
    "* 두 번째 미니배치는 500번째 데이터로 시작 위치를 정하고 그 위치부터 순서대로 데이터 제공(500만큼 시작 위치 옮긴다.). \n",
    "![img](./images/fig_5-15.png)  \n",
    "\n",
    "* 이후로는 순서대로 진행되므로 다음 데이터는 각각 시계열 데이터의 10~19번째 데이터 + 510 ~ 519 번째 데이터가 된다.\n",
    "* 미니배치 시작 위치를 오프셋으로 옮긴 후 순서대로 제공하고, 끝에 도달하면 다시 처음부터 입력한다.\n",
    "\n",
    "* 주의사항 : 데이터 제공 방법 측면\n",
    "    * 데이터 순서대로 제공하기\n",
    "    * 미니배치별로 데이터 제공하는 시작 위치 옮기기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 구현\n",
    "\n",
    "가로 방향으로 성장한 신경망 구현  \n",
    "Truncated BPTT 방식으로, 가로 크기가 일정한 일련의 신경망 제작하면 다음과 같다.\n",
    "![img](./images/fig_5-16.png)\n",
    "\n",
    "* 길이가 T인 시계열 데이터 받는다.  \n",
    "* 각 시각 은닉 상태를 T개 출력한다.\n",
    "* 그림의 신경망을 하나의 계층으로 구현한다.  \n",
    "\n",
    "![img](./images/fig_5-17.png)\n",
    "\n",
    "* 상하 방향 입력과 출력을 각각 하나로 묶으면 옆으로 늘어선 일련의 계층을 하나로 간주한다.\n",
    "* RNN 계층:  Time RNN 계층 내에서 한 단계의 작업을 수행하는 계층\n",
    "* Time RNN 계층 : T개 단계분의 작업을 한꺼번에 처리하는 계층\n",
    "\n",
    "\n",
    "* 구현의 흐름\n",
    "    * RNN 클래스 : RNN 한 단계 처리하는 클래스\n",
    "    * TimeRNN 클래스 : RNN 클래스로 T개 단계의 처리를 한꺼번에 수행하는 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 계층 구현\n",
    "RNN 클래스 구현 : RNN 순전파 수식은 다음과 같다.\n",
    "$$\\mathbf{h_t} = \\tanh(\\mathbf{h_{t-1}}\\mathbf{W_h} + \\mathbf{x_t}\\mathbf{ W_x} + \\mathbf{b})$$\n",
    "\n",
    "데이터는 미니배치로 모아 처리한다. 그래서 샘플 데이터($x_t, h_t$)를 행 방향에 저장한다.  \n",
    "행렬 연산이므로 각 행렬의 형상 확인이 중요하다.  \n",
    "미니배치 크기 N, 입력 벡터 차원의 수 D, 은닉 상태 벡터의 차원 수 H이면 형상 확인은 다음과 같다.\n",
    "\n",
    "![img](./images/fig_5-18.png)\n",
    "형상 확인을 통해 올바로 구현하는지 확인 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 클래스의 초기화와 순전파 메서드 구현\n",
    "class RNN:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        t = np.matmul(h_prev, Wh) + np.matmul(x, Wx) + b\n",
    "        h_next = np.tanh(t)\n",
    "        \n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        return h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 초기화 메서드 : 가중치 2개와 편향 1개 인수로 받는다.  \n",
    "    * 인수로 받은 매개변수를 인스턴스 변수 params에 리스트로 저장  \n",
    "    * 각 매개변수 대응하는 기울기 초기화 후 grads 저장  \n",
    "    * 역전파 계산 시 사용하는 중간 데이터 담을 cache를 None 초기화.  \n",
    "\n",
    "* 순전파 forward(x, h_prev) 메서드 : 인수 2개(아래 입력 x, 왼쪽 입력 h_prev)\n",
    "    * 하나 앞의 RNN 계층 입력 : h_prev\n",
    "    * 현 시각 출력 혹은 다음 시각 계층으로 입력 : h_next\n",
    "![img](./images/fig_5-19.png)\n",
    "\n",
    "순전파를 계산 그래프로 나타낸다. 편향 b의 덧셈은 브로드캐스트 일어나므로 Repeat 노드 이용. (생략)\n",
    "* 역전파 : 순전파 반대방향으로 고려\n",
    "![img](./images/fig_5-20.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 계층의 backward() 코드\n",
    "def backward(self, dh_next):\n",
    "    Wx, Wh, b = self.params\n",
    "    x, h_prev, h_next = self.cache\n",
    "    \n",
    "    dt = dh_next * (1-h_next ** 2)\n",
    "    db = np.sum(dt, axis=0)\n",
    "    dWh = np.matmul(h_prev.T, dt)\n",
    "    dh_prev = np.matmul(dt, Wh.T)\n",
    "    dWx = np.matmul(x.T, dt)\n",
    "    dx = np.matmul(dt, Wx.T)\n",
    "    \n",
    "    self.grads[0][...] = dWx\n",
    "    self.grads[1][...] = dWh\n",
    "    self.grads[2][...] = db\n",
    "    \n",
    "    return dx, dh_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time RNN 계층 구현\n",
    "\n",
    "![img](./images/fig_5-21.png)\n",
    "Time RNN 계층 : RNN 계층 T개를 연결한 신경망\n",
    "RNN 계층의 은닉 상태 h : 인스턴스 변수 유지 : 은닉 상태를 **인계**받는 용도로 이용\n",
    "\n",
    "![img](./images/fig_5-22.png)\n",
    "RNN 계층의 은닉 상태를 Time RNN 계층에서 관리한다.\n",
    "은닉 상태를 인계하는 작업을 생각하지 않아도 된다. 이를 stateful 인수로 조정 가능하도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time RNN 계층\n",
    "import numpy as np\n",
    "class TImeRNN:\n",
    "    def __init(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        \n",
    "        self.h, self.dh = None, None\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.h = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 초기화 메서드 : 가중치, 편향, stateful(불리언 값) 인수\n",
    "* layers 변수 : 다수의 RNN 계층을 리스트로 저장 용도\n",
    "* h : foward() 메서드에서 마지막 RNN 계층의 은닉 상태 저장\n",
    "* dh : backward() 불렀을 때, _하나 앞 블록의 은닉 상태 기울기_ 저장\n",
    "* stateful : 상태가 있는\n",
    "    * True : Time RNN 계층이 상태가 있다(은닉 상태를 유지한다) 순전파를 끊지 않고 전파한다.\n",
    "    * False : 은닉 상태를 영행렬로 초기화(=상태가 없는 모드, 무상태)\n",
    "    \n",
    "* 긴 시계열 데이터 처리 : RNN 은닉 상태를 유지해야 한다. : stateful 단어로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순전파 구현\n",
    "def forward(self, xs):\n",
    "    Wx, Wh, b = self.params\n",
    "    N, T, D = xs.shape\n",
    "    D, H = Wx.shape\n",
    "    \n",
    "    self.layers = []\n",
    "    hs = np.empty((N, T, H), dype = 'f')\n",
    "    \n",
    "    if not self.stateful or self.h is None:\n",
    "        self.h = np.zeros((N, H), dype = 'f')\n",
    "        \n",
    "    for t in range(T):\n",
    "        layer = RNN(*self.params)\n",
    "        self.h = layer.forward(xs[:, t, :]. self.h)\n",
    "        hs[:, t, :] = self.h\n",
    "        self.layers.append(layer)\n",
    "        \n",
    "    return hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Time RNN 계층의 역전파\n",
    "![img](./images/fig_5-23.png)\n",
    "\n",
    "![img](./images/fig_5-24.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, dhs):\n",
    "    Wx, Wh, b = self.params\n",
    "    N, T, H = dhs.shape\n",
    "    D, H = Wx.shape\n",
    "    \n",
    "    dxs = np.empty((N, T, D), dtype = 'f')\n",
    "    dh = 0\n",
    "    grads = [0,0,0]\n",
    "    for t in reversed(range(T)):\n",
    "        layer = self.layers[t]\n",
    "        dx, dh = layer.backward(dhs[:, t, :] + dh) #합산 기울기\n",
    "        dxs[:, t, :] = dx\n",
    "        \n",
    "        for i, grad in enumerate(layer.grads):\n",
    "            grads[i] += grad\n",
    "            \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        \n",
    "        return dxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시계열 데이터 처리 계층 구현\n",
    "### RNNLM의 전체 그림\n",
    "![img](./images/fig_5-25.png)\n",
    "![img](./images/fig_5-26.png)\n",
    "\n",
    "### Time 계층 구현\n",
    "* Time XX 계층\n",
    "![img](./images/fig_5-27.png)\n",
    "\n",
    "* Time Affine 계층\n",
    "![img](./images/fig_5-28.png)\n",
    "\n",
    "* Time Softmax with Loss 계층\n",
    "![img](./images/fig_5-29.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNLM 학습과 평가\n",
    "### RNNLM 구현\n",
    "* SimpleRnnlm의 계층 구성\n",
    "![img](./images/fig_5-30.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleRnnlm 클래스\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.time_layers import *\n",
    "\n",
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "        \n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Affine, RNN layer에서 Xavier 초기값을 사용했다.\n",
    "* 이전 노드 n개이면, 표준편차가 $1 \\over {\\sqrt{n}}$ 인 분포로 값을 초기화\n",
    "![img](./images/fig_5-31.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward, backward, reset_state() 메서드\n",
    "def forward(self, xs, ts):\n",
    "    for layer in self.layers:\n",
    "        xs = layer.forward(xs)\n",
    "    loss = self.loss_layer.forward(xs, ts)\n",
    "    return loss\n",
    "\n",
    "def backward(self, dout =1):\n",
    "    dout = self.loss_layer.backward(dout)\n",
    "    for layer in reversed(self.layers):\n",
    "        dout = layer.backward(dout)\n",
    "    return dout\n",
    "\n",
    "def reset_state(self):\n",
    "    self.rnn_layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* reset_state() : 신경망 상태를 초기화하는 편의 메서드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 언어 모델의 평가\n",
    "* 퍼플렉시티(perplexity, 혼란도) : 언어 모델 예측 성능을 평가하는 척도\n",
    "* 확률의 역수(특히 데이터 수가 하나일 때 일치)\n",
    "![img](./images/fig_5-32.png)\n",
    "* 퍼플렉시티가 작을수록 성능이 좋다.\n",
    "* 해석 : 분기 수(number of branches)\n",
    "    * 다음에 취할 수 있는 선택사항의 수(단어 후보의 수)\n",
    "    * 1.25 분기수 = 다음 출현할 수 있는 단어 후보를 1개 정도로 좁힌다.\n",
    "    \n",
    "* 입력 데이터가 여러 개인 경우\n",
    "\n",
    "$$L = -{1 \\over N} \\sum_n \\sum_k t_{nk} \\log y_{nk} \\\\ perplexity = e^L$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말뭉치 크기: 1000, 어휘 수: 418\n",
      "| 에폭 1 | 퍼플렉서티 379.99\n",
      "| 에폭 2 | 퍼플렉서티 250.72\n",
      "| 에폭 3 | 퍼플렉서티 223.82\n",
      "| 에폭 4 | 퍼플렉서티 215.59\n",
      "| 에폭 5 | 퍼플렉서티 207.52\n",
      "| 에폭 6 | 퍼플렉서티 202.99\n",
      "| 에폭 7 | 퍼플렉서티 199.19\n",
      "| 에폭 8 | 퍼플렉서티 196.72\n",
      "| 에폭 9 | 퍼플렉서티 191.69\n",
      "| 에폭 10 | 퍼플렉서티 192.96\n",
      "| 에폭 11 | 퍼플렉서티 189.05\n",
      "| 에폭 12 | 퍼플렉서티 191.80\n",
      "| 에폭 13 | 퍼플렉서티 189.94\n",
      "| 에폭 14 | 퍼플렉서티 191.02\n",
      "| 에폭 15 | 퍼플렉서티 189.16\n",
      "| 에폭 16 | 퍼플렉서티 185.82\n",
      "| 에폭 17 | 퍼플렉서티 183.30\n",
      "| 에폭 18 | 퍼플렉서티 180.06\n",
      "| 에폭 19 | 퍼플렉서티 180.59\n",
      "| 에폭 20 | 퍼플렉서티 180.76\n",
      "| 에폭 21 | 퍼플렉서티 178.73\n",
      "| 에폭 22 | 퍼플렉서티 175.18\n",
      "| 에폭 23 | 퍼플렉서티 171.91\n",
      "| 에폭 24 | 퍼플렉서티 172.00\n",
      "| 에폭 25 | 퍼플렉서티 171.78\n",
      "| 에폭 26 | 퍼플렉서티 170.92\n",
      "| 에폭 27 | 퍼플렉서티 165.09\n",
      "| 에폭 28 | 퍼플렉서티 162.01\n",
      "| 에폭 29 | 퍼플렉서티 160.79\n",
      "| 에폭 30 | 퍼플렉서티 152.71\n",
      "| 에폭 31 | 퍼플렉서티 154.04\n",
      "| 에폭 32 | 퍼플렉서티 146.89\n",
      "| 에폭 33 | 퍼플렉서티 146.51\n",
      "| 에폭 34 | 퍼플렉서티 139.93\n",
      "| 에폭 35 | 퍼플렉서티 136.74\n",
      "| 에폭 36 | 퍼플렉서티 131.50\n",
      "| 에폭 37 | 퍼플렉서티 126.73\n",
      "| 에폭 38 | 퍼플렉서티 123.16\n",
      "| 에폭 39 | 퍼플렉서티 116.64\n",
      "| 에폭 40 | 퍼플렉서티 110.03\n",
      "| 에폭 41 | 퍼플렉서티 111.25\n",
      "| 에폭 42 | 퍼플렉서티 102.98\n",
      "| 에폭 43 | 퍼플렉서티 97.63\n",
      "| 에폭 44 | 퍼플렉서티 93.23\n",
      "| 에폭 45 | 퍼플렉서티 90.85\n",
      "| 에폭 46 | 퍼플렉서티 88.49\n",
      "| 에폭 47 | 퍼플렉서티 83.08\n",
      "| 에폭 48 | 퍼플렉서티 77.44\n",
      "| 에폭 49 | 퍼플렉서티 75.71\n",
      "| 에폭 50 | 퍼플렉서티 71.87\n",
      "| 에폭 51 | 퍼플렉서티 66.90\n",
      "| 에폭 52 | 퍼플렉서티 64.29\n",
      "| 에폭 53 | 퍼플렉서티 61.44\n",
      "| 에폭 54 | 퍼플렉서티 59.57\n",
      "| 에폭 55 | 퍼플렉서티 54.70\n",
      "| 에폭 56 | 퍼플렉서티 51.19\n",
      "| 에폭 57 | 퍼플렉서티 48.95\n",
      "| 에폭 58 | 퍼플렉서티 45.54\n",
      "| 에폭 59 | 퍼플렉서티 42.78\n",
      "| 에폭 60 | 퍼플렉서티 40.44\n",
      "| 에폭 61 | 퍼플렉서티 39.62\n",
      "| 에폭 62 | 퍼플렉서티 37.01\n",
      "| 에폭 63 | 퍼플렉서티 33.86\n",
      "| 에폭 64 | 퍼플렉서티 32.29\n",
      "| 에폭 65 | 퍼플렉서티 32.36\n",
      "| 에폭 66 | 퍼플렉서티 29.42\n",
      "| 에폭 67 | 퍼플렉서티 28.60\n",
      "| 에폭 68 | 퍼플렉서티 25.69\n",
      "| 에폭 69 | 퍼플렉서티 23.44\n",
      "| 에폭 70 | 퍼플렉서티 23.79\n",
      "| 에폭 71 | 퍼플렉서티 22.09\n",
      "| 에폭 72 | 퍼플렉서티 21.00\n",
      "| 에폭 73 | 퍼플렉서티 19.48\n",
      "| 에폭 74 | 퍼플렉서티 18.26\n",
      "| 에폭 75 | 퍼플렉서티 17.72\n",
      "| 에폭 76 | 퍼플렉서티 16.13\n",
      "| 에폭 77 | 퍼플렉서티 15.51\n",
      "| 에폭 78 | 퍼플렉서티 14.67\n",
      "| 에폭 79 | 퍼플렉서티 13.40\n",
      "| 에폭 80 | 퍼플렉서티 12.99\n",
      "| 에폭 81 | 퍼플렉서티 13.38\n",
      "| 에폭 82 | 퍼플렉서티 12.47\n",
      "| 에폭 83 | 퍼플렉서티 11.48\n",
      "| 에폭 84 | 퍼플렉서티 10.50\n",
      "| 에폭 85 | 퍼플렉서티 10.62\n",
      "| 에폭 86 | 퍼플렉서티 10.27\n",
      "| 에폭 87 | 퍼플렉서티 9.65\n",
      "| 에폭 88 | 퍼플렉서티 8.44\n",
      "| 에폭 89 | 퍼플렉서티 8.28\n",
      "| 에폭 90 | 퍼플렉서티 8.31\n",
      "| 에폭 91 | 퍼플렉서티 7.79\n",
      "| 에폭 92 | 퍼플렉서티 7.20\n",
      "| 에폭 93 | 퍼플렉서티 6.83\n",
      "| 에폭 94 | 퍼플렉서티 6.89\n",
      "| 에폭 95 | 퍼플렉서티 6.52\n",
      "| 에폭 96 | 퍼플렉서티 5.85\n",
      "| 에폭 97 | 퍼플렉서티 5.60\n",
      "| 에폭 98 | 퍼플렉서티 5.28\n",
      "| 에폭 99 | 퍼플렉서티 5.34\n",
      "| 에폭 100 | 퍼플렉서티 5.16\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from dataset import ptb\n",
    "from simple_rnnlm import SimpleRnnlm\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100 # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 5     # Truncated BPTT가 한 번에 펼치는 시간 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습 데이터 읽기(전체 중 1000개만)\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1]  # 입력\n",
    "ts = corpus[1:]   # 출력(정답 레이블)\n",
    "data_size = len(xs)\n",
    "print('말뭉치 크기: %d, 어휘 수: %d' % (corpus_size, vocab_size))\n",
    "\n",
    "# 학습 시 사용하는 변수\n",
    "max_iters = data_size // (batch_size * time_size)\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "# 미니배치의 각 샘플의 읽기 시작 위치를 계산\n",
    "jump = (corpus_size - 1) // batch_size\n",
    "offsets = [i * jump for i in range(batch_size)]\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # 미니배치 취득\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "\n",
    "        # 기울기를 구하여 매개변수 갱신\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "    # 에폭마다 퍼플렉서티 평가\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| 에폭 %d | 퍼플렉서티 %.2f'\n",
    "          % (epoch+1, ppl))\n",
    "    ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "x = np.arange(len(ppl_list))\n",
    "plt.plot(x, ppl_list, label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('perplexity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 크기가 작은 말뭉치로 실험했을 때, 학습이 진행할수록 퍼플렉서티가 순조롭게 낮아진다.\n",
    "* 큰 말뭉치는 대응 불가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNNLM의 Trainer 클래스\n",
    "RnnlmTrainer 클래스\n",
    "\n",
    "    from common.trainer import RnnlmTrainer\n",
    "\n",
    "    model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "    optimizer = SGD(lr)\n",
    "    trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "    trainer.fit(xs, ts, max_epoch, batch_size, time_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 미니배치를 **순차적**으로 만들기\n",
    "2. 모델의 순전파와 역전파를 호출\n",
    "3. 옵티마이저로 가중치 갱신\n",
    "4. 퍼플렉서티 구한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "* RNN 순환하는 경로가 있고 이를 통해 내부에 은닉 상태를 기억할 수 있다.\n",
    "* RNN의 순환 경로를 펼쳐서 다수의 RNN 계층이 연결된 신경망으로 해석할 수 있으며 보통의 오차역전파법으로 학습 가능하다.(=BPTT)\n",
    "* 긴 시계열 데이터를 학습할 때는 데이터를 적당한 길이씩 모으고(블록), 블록 단위로 BPTT에 의한 학습을 수행(truncated BPTT)\n",
    "* Truncated BPTT : 역전파의 연결만 끊는다.\n",
    "* Truncated BPTT : 순전파 연결을 유지하기 위해 데이터를 순차적으로 입력해야 한다.\n",
    "* 언어 모델은 단어 시퀸스를 확률로 해석한다.\n",
    "* RNN 계층을 이용한 조건부 언어 모델은 이론적으로 그때까지 등장한 모든 단어의 정보를 기억할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
