{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8 어텐션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 어텐션의 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어텐션은 seq2seq를 필요한 정보에만 주목할 수 있도록 한다. 이를 통해 seq2seq가 갖고 있는 문제를 해결할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.1 seq2seq의 문제점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전의 seq2seq는 Encoder가 고정 길이의 벡터를 출력했다. 아무리 긴 문장이 있더라도 고정된 길이의 벡터로 반환해야 하기 때문에 한계가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.2 Encoder 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시각 별 LSTM 계층의 은닉 상태 벡터를 모두 사용한다. 이렇게 되면 입력된 단어 길이와 같은 수의 벡터를 얻을 수 있다. \n",
    "\n",
    "여러 딥러닝 프레임워크에서 RNN 계층을 초기화할 때 모든 시각의 은닉 상태 벡터 변환과 마지막 은닉 상태 벡터만 반환 둘 중 하나로 설정할 수 있다.\n",
    "\n",
    "각 시각의 은닉 상태에는 해당 시각에 입력된 단어의 정보가 많이 담겨 있을 것이다. 추가적으로, 문장에서 단어의 정보는 주변 정보를 균형 있게 담아야 하기 때문에 양방향 RNN이나 양방향 LSTM을 사용하면 효과적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.3 Decoder 개선 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**얼라인먼트(alignment)**: 단어(혹은 문구)의 대응 관계를 나타내는 정보, 이전까지는 사람의 수작업으로 만들어졌다. 어텐션은 이를 자동으로 수행한다.\n",
    "\n",
    "필요한 정보에만 주목해서 그 정보로부터 시계열 변환을 수행하는 것을 어텐션이라고 한다.\n",
    "\n",
    "<img src='./images/fig8-6.png' width=700>\n",
    "\n",
    "위의 어떤 계산의 입력으로는 Encoder로부터 온 hs와 시각별 LSTM 계층의 은닉 상태이다. 필요한 정보만 골라 Affine 계층으로 출력한다. Encoder의 마지막 은닉 상태 벡터는 여전히 Decoder의 첫번째 LSTM 계층로 전달된다.\n",
    "\n",
    "위의 어떤 계산은 Decoder에서 출력을 할 때 필요한 정보를 hs에서 선택하는 과정이다. 하지만 선택하는 작업은 미분할 수 없다는 문제가 있다. 이 문제를 **전체를 선택한 후 각 단어의 가중치를 별도로 계산하는 문제로 치환**하면 미분이 가능해진다.\n",
    "\n",
    "<img src=\"./images/fig8-8.png\" width=600>\n",
    "\n",
    "각 단어의 중요도를 나타내는 가중치 a(확률분포와 유사)를 구한 후 단어 벡터 hs와 가중합을 계산해서 맥락 벡터 c를 구한다. 위의 예시에서 '나'에 대응하는 가중치가 0.8이었으니 맥락 벡터에는 '나' 벡터의 성분이 많이 포함되어 있다. 맥락 벡터 c에는 현 시각의 변환을 수행하는데 필요한 정보가 담겨 있어야 하고, 결국 이렇게 학습하도록하는 것이 궁극적인 목표이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n",
      "(5, 4)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "# 형상에 주목\n",
    "T, H = 5, 4\n",
    "hs = np.random.randn(T, H)\n",
    "a = np.array([0.8, 0.1, 0.03, 0.05, 0.02])\n",
    "\n",
    "ar = a.reshape(5, 1).repeat(4, axis=1)\n",
    "print(ar.shape)\n",
    "\n",
    "t = hs * ar\n",
    "print(t.shape)\n",
    "\n",
    "c = np.sum(t, axis=0)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구현에서 repeat 대신 브로드캐스트를 이용하는 것이 더욱 효율적이다. 브로드캐스트를 하더라도 Repeat 노드에 해당하므로 Repeat 노드의 역전파를 수행해야 한다. 단, 가장 효율적으로 가중합을 구하는 방식은 행렬 곱을 이용하는 것이다. 이 방식은 미니배치 처리로 확장하기 쉽지 않고, 미니배치로 구현하려면 텐서 곱이라는 개념이 필요하다(np.tensordot()과 np.einsum() 사용).\n",
    "\n",
    "#### axis 매개 변수 사용법\n",
    "- np.repeat: 반복을 수행할 축\n",
    "- np.sum: 합을 구해서 사라지게 할 축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 4)\n",
      "(10, 4)\n"
     ]
    }
   ],
   "source": [
    "# 미니배치 처리용 가중합 구현\n",
    "N, T, H = 10, 5, 4\n",
    "hs = np.random.randn(N, T, H)\n",
    "a = np.random.randn(N, T)\n",
    "ar = a.reshape(N, T, 1).repeat(H, axis=2)\n",
    "# ar = a.reshape(N, T, 1) # 브로드캐스트를 사용하는 경우\n",
    "\n",
    "t = hs * ar\n",
    "print(t.shape)\n",
    "\n",
    "c = np.sum(t, axis=1)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightSum:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], [] # params는 사용하지 않으나 구현 규칙에 따라 만들어주었다.\n",
    "        self.cache = None\n",
    "        \n",
    "        \n",
    "    def forward(self, hs, a):\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        ar = a.reshape(N, T, 1).repeat(H, axis=2)\n",
    "        t = hs * ar\n",
    "        c = np.sum(t, axis=1)\n",
    "        \n",
    "        self.cache = (hs, ar)\n",
    "        \n",
    "        return c\n",
    "    \n",
    "    \n",
    "    def backward(self, dc):\n",
    "        hs, ar = self.cache\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        dt = dc.reshape(N, 1, H).repeat(T, axis=1)\n",
    "        dar = dt * hs\n",
    "        dhs = dt * ar\n",
    "        da = np.sum(dar, axis=2)\n",
    "        \n",
    "        return dhs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.4 Decoder 개선 - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치 a도 데이터로부터 자동으로 학습할 수 있도록 해야 한다.\n",
    "\n",
    "Decoder의 LSTM 계층의 은닉 상태 벡터(h)와 Encoder의 마지막 시각의 hs 사이의 유사도는 벡터의 내적으로 구할 수 있다. 내적은 두 벡터가 얼마나 같은 방향을 향하고 있는지를 나타낸다. 내적을 하면 정규화하기 전의 점수 s를 구할 수 있다. s는 일반적으로 소프트맥스 함수를 거쳐 정규화해 가중치 a를 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.layers import Softmax\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 4)\n",
      "(10, 5)\n",
      "(10, 5)\n"
     ]
    }
   ],
   "source": [
    "N, T, H = 10, 5, 4\n",
    "hs = np.random.randn(N, T, H)\n",
    "h = np.random.randn(N, H)\n",
    "hr = h.reshape(N, 1, H)\n",
    "\n",
    "t = hs * hr\n",
    "print(t.shape)\n",
    "\n",
    "s = np.sum(t, axis=2)\n",
    "print(s.shape)\n",
    "\n",
    "softmax = Softmax()\n",
    "a = softmax.forward(s)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.np import *\n",
    "from common.layers import Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWeight:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.softmax = Softmax()\n",
    "        self.cache = None\n",
    "        \n",
    "    \n",
    "    def forward(self, hs, h):\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        hr = h.reshape(N, 1, H).repeat(T, axis=1)\n",
    "        t = hs * hr\n",
    "        s = np.sum(t, axis=2)\n",
    "        a = self.softmax.forward(s)\n",
    "        \n",
    "        self.cache = (hs, hr)\n",
    "        return a\n",
    "    \n",
    "    \n",
    "    def backward(self, da):\n",
    "        hs, hr = self.cache\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        ds = self.softmax.backward(da)\n",
    "        dt = ds.reshape(N, T, 1).repeat(H, axis=2)\n",
    "        dhs = dt * hr\n",
    "        dhr = dt * hs\n",
    "        dh = np.sum(dhr, axis=1)\n",
    "        \n",
    "        return dhs, dh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.5 Decoder 개선 - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig8-16.png\" width=600>\n",
    "\n",
    "방금까지 본 계층을 Weight Sum, Attention Weight 게층이라고 하고, 이 둘을 합쳐서 Attention 계층이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.attention_weight_layer = AttentionWeight()\n",
    "        self.weight_sum_layer = WeightSum()\n",
    "        self.attention_weight = None\n",
    "        \n",
    "        \n",
    "    def forward(self, hs, h):\n",
    "        a = self.attention_weight_layer.forward(hs, h)\n",
    "        out = self.weight_sum_layer.forward(hs, a)\n",
    "        self.attention_weight = a\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dhs0, da = self.weight_sum_layer.backward(dout)\n",
    "        dhs1, dh = self.attention_weight_layer.backward(da)\n",
    "        dhs = dhs0 + dhs1\n",
    "        \n",
    "        return dhs, dh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig8-18.png\" width=700>\n",
    "\n",
    "Affine 계층에 맥락 벡터와 은닉 상태 벡터가 입력된다.\n",
    "\n",
    "이전과 마찬가지로 다수의 Attention 계층을 모아 Time Attention 계층으로 만들 수 있다.\n",
    "\n",
    "<img src=\"./images/fig8-20.png\" width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeAttention:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.layers = None\n",
    "        self.attention_weights = None\n",
    "        \n",
    "        \n",
    "    def forward(self, hs_enc, hs_dec):\n",
    "        N, T, H = hs_dec.shape\n",
    "        out = np.empty_like(hs_dec)\n",
    "        self.layers = []\n",
    "        self.attention_weights = []\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = Attention()\n",
    "            out[:, t, :] = layer.forward(hs_enc, hs_dec[:, t, :])\n",
    "            self.layers.append(layer)\n",
    "            self.attention_weights.append(layer.attention_weight)\n",
    "            \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def backward(self, dout):\n",
    "        N, T, H = dout.shape\n",
    "        dhs_enc = 0\n",
    "        dhs_dec = np.empty_like(dout)\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            dhs, dh = layer.backward(dout[:, t, :])\n",
    "            dhs_enc += dhs\n",
    "            dhs_dec[:, t, :] = dh\n",
    "            \n",
    "        return dhs_enc, dhs_dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 어텐션을 갖춘 seq2seq 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.1 Encoder 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 은닉 상태 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.time_layers import *\n",
    "from seq2seq import Encoder, Seq2seq\n",
    "from attention_layer import TimeAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionEncoder(Encoder):\n",
    "    \n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        \n",
    "        return hs\n",
    "    \n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dout)\n",
    "        \n",
    "        return dout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2 Decoder 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder:\n",
    "    \n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(2*H, V) / np.sqrt(2*H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
    "        self.attention = TimeAttention()\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "        layers = [self.embed, self.lstm, self.attention, self.affine]\n",
    "        \n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "        \n",
    "    def forward(self, xs, enc_hs):\n",
    "        h = enc_hs[:, -1]\n",
    "        self.lstm.set_state(h)\n",
    "        \n",
    "        out = self.embed.forward(xs)\n",
    "        dec_hs = self.lstm.forward(out)\n",
    "        c = self.attention.forward(enc_hs, dec_hs)\n",
    "        out = np.concatenate((c, dec_hs), axis=2)\n",
    "        score = self.affine.forward(out)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    \n",
    "    def backward(self, dscore):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def generate(self, enc_hs, start_id, sample_size):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.3 seq2seq 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq import Encoder, Seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionSeq2seq(Seq2seq):\n",
    "    \n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        args = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = AttentionEncoder(*args)\n",
    "        self.decoder = AttentionDecoder(*args)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "        \n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 어텐션 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "날짜 형식 변경 문제  \n",
    "번역용 데이터셋 중에서는 WMT가 있으나 너무 커서 날짜 형식 변경 문제로 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.1 날짜 형식 변환 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사람이 쓴 날짜 데이터(형식에 맞추지 않음)를 표준 형식(YYYY-MM-DD)으로 변환\n",
    "\n",
    "문제1. 사람이 쓴 날짜 데이터의 형식은 매우 많으므로 수작업으로 해당 패턴을 찾아서 변환 규칙을 만드는 것은 매우 번거롭다.  \n",
    "문제2. 입력과 출력의 대응 관계를 쉽게 알 수 있다.\n",
    "\n",
    "<img src=\"./images/fig8-23.png\" width=500>\n",
    "\n",
    "입력과 출력의 구분 문자는 \\_, 출력의 끝은 출력의 길이가 모두 동일하므로 따로 두지 않았다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.2 어텐션을 갖춘 seq2seq의 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataset import sequence\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n",
    "from attention_seq2seq import AttentionSeq2seq\n",
    "from seq2seq import Seq2seq\n",
    "from peeky_seq2seq import PeekySeq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 351 | 시간 0[s] | 손실 4.08\n",
      "| 에폭 1 |  반복 21 / 351 | 시간 10[s] | 손실 3.09\n",
      "| 에폭 1 |  반복 41 / 351 | 시간 20[s] | 손실 1.90\n",
      "| 에폭 1 |  반복 61 / 351 | 시간 30[s] | 손실 1.72\n",
      "| 에폭 1 |  반복 81 / 351 | 시간 40[s] | 손실 1.46\n",
      "| 에폭 1 |  반복 101 / 351 | 시간 50[s] | 손실 1.19\n",
      "| 에폭 1 |  반복 121 / 351 | 시간 60[s] | 손실 1.14\n",
      "| 에폭 1 |  반복 141 / 351 | 시간 71[s] | 손실 1.09\n",
      "| 에폭 1 |  반복 161 / 351 | 시간 81[s] | 손실 1.06\n",
      "| 에폭 1 |  반복 181 / 351 | 시간 91[s] | 손실 1.04\n",
      "| 에폭 1 |  반복 201 / 351 | 시간 101[s] | 손실 1.03\n",
      "| 에폭 1 |  반복 221 / 351 | 시간 111[s] | 손실 1.02\n",
      "| 에폭 1 |  반복 241 / 351 | 시간 121[s] | 손실 1.02\n",
      "| 에폭 1 |  반복 261 / 351 | 시간 131[s] | 손실 1.01\n",
      "| 에폭 1 |  반복 281 / 351 | 시간 141[s] | 손실 1.00\n",
      "| 에폭 1 |  반복 301 / 351 | 시간 152[s] | 손실 1.00\n",
      "| 에폭 1 |  반복 321 / 351 | 시간 162[s] | 손실 1.00\n",
      "| 에폭 1 |  반복 341 / 351 | 시간 172[s] | 손실 1.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "X 1978-08-11\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "X 1978-08-11\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "X 1978-08-11\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "X 1978-08-11\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "X 1978-08-11\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "X 1978-08-11\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "X 1978-08-11\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "X 1978-08-11\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "X 1978-08-11\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "X 1978-08-11\n",
      "---\n",
      "val acc 0.000%\n",
      "| 에폭 2 |  반복 1 / 351 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 2 |  반복 21 / 351 | 시간 10[s] | 손실 1.00\n",
      "| 에폭 2 |  반복 41 / 351 | 시간 20[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 61 / 351 | 시간 30[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 81 / 351 | 시간 40[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 101 / 351 | 시간 51[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 121 / 351 | 시간 61[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 141 / 351 | 시간 71[s] | 손실 0.98\n",
      "| 에폭 2 |  반복 161 / 351 | 시간 81[s] | 손실 0.98\n",
      "| 에폭 2 |  반복 181 / 351 | 시간 91[s] | 손실 0.97\n",
      "| 에폭 2 |  반복 201 / 351 | 시간 102[s] | 손실 0.95\n",
      "| 에폭 2 |  반복 221 / 351 | 시간 112[s] | 손실 0.94\n",
      "| 에폭 2 |  반복 241 / 351 | 시간 122[s] | 손실 0.90\n",
      "| 에폭 2 |  반복 261 / 351 | 시간 133[s] | 손실 0.83\n",
      "| 에폭 2 |  반복 281 / 351 | 시간 144[s] | 손실 0.74\n",
      "| 에폭 2 |  반복 301 / 351 | 시간 155[s] | 손실 0.66\n",
      "| 에폭 2 |  반복 321 / 351 | 시간 166[s] | 손실 0.58\n",
      "| 에폭 2 |  반복 341 / 351 | 시간 176[s] | 손실 0.47\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "X 2006-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "X 2007-08-09\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "X 1983-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "X 2016-11-08\n",
      "---\n",
      "val acc 51.360%\n",
      "| 에폭 3 |  반복 1 / 351 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 3 |  반복 21 / 351 | 시간 10[s] | 손실 0.30\n",
      "| 에폭 3 |  반복 41 / 351 | 시간 21[s] | 손실 0.21\n",
      "| 에폭 3 |  반복 61 / 351 | 시간 31[s] | 손실 0.14\n",
      "| 에폭 3 |  반복 81 / 351 | 시간 41[s] | 손실 0.09\n",
      "| 에폭 3 |  반복 101 / 351 | 시간 51[s] | 손실 0.07\n",
      "| 에폭 3 |  반복 121 / 351 | 시간 61[s] | 손실 0.05\n",
      "| 에폭 3 |  반복 141 / 351 | 시간 72[s] | 손실 0.04\n",
      "| 에폭 3 |  반복 161 / 351 | 시간 82[s] | 손실 0.03\n",
      "| 에폭 3 |  반복 181 / 351 | 시간 92[s] | 손실 0.03\n",
      "| 에폭 3 |  반복 201 / 351 | 시간 103[s] | 손실 0.02\n",
      "| 에폭 3 |  반복 221 / 351 | 시간 113[s] | 손실 0.02\n",
      "| 에폭 3 |  반복 241 / 351 | 시간 123[s] | 손실 0.02\n",
      "| 에폭 3 |  반복 261 / 351 | 시간 133[s] | 손실 0.01\n",
      "| 에폭 3 |  반복 281 / 351 | 시간 144[s] | 손실 0.01\n",
      "| 에폭 3 |  반복 301 / 351 | 시간 154[s] | 손실 0.01\n",
      "| 에폭 3 |  반복 321 / 351 | 시간 164[s] | 손실 0.01\n",
      "| 에폭 3 |  반복 341 / 351 | 시간 174[s] | 손실 0.01\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "O 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "O 2016-11-06\n",
      "---\n",
      "val acc 99.900%\n",
      "| 에폭 4 |  반복 1 / 351 | 시간 0[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 21 / 351 | 시간 10[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 41 / 351 | 시간 20[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 61 / 351 | 시간 31[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 81 / 351 | 시간 41[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 101 / 351 | 시간 51[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 121 / 351 | 시간 61[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 141 / 351 | 시간 72[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 161 / 351 | 시간 82[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 181 / 351 | 시간 93[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 201 / 351 | 시간 105[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 221 / 351 | 시간 116[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 241 / 351 | 시간 126[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 261 / 351 | 시간 136[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 281 / 351 | 시간 147[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 301 / 351 | 시간 157[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 321 / 351 | 시간 167[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 341 / 351 | 시간 177[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "O 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "O 2016-11-06\n",
      "---\n",
      "val acc 99.900%\n",
      "| 에폭 5 |  반복 1 / 351 | 시간 0[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 21 / 351 | 시간 10[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 41 / 351 | 시간 21[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 61 / 351 | 시간 31[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 81 / 351 | 시간 41[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 101 / 351 | 시간 52[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 121 / 351 | 시간 62[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 141 / 351 | 시간 72[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 161 / 351 | 시간 82[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 181 / 351 | 시간 93[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 201 / 351 | 시간 103[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 221 / 351 | 시간 113[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 241 / 351 | 시간 123[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 261 / 351 | 시간 133[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 281 / 351 | 시간 143[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 301 / 351 | 시간 154[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 321 / 351 | 시간 164[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 341 / 351 | 시간 174[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "O 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "O 2016-11-06\n",
      "---\n",
      "val acc 99.940%\n",
      "| 에폭 6 |  반복 1 / 351 | 시간 0[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 21 / 351 | 시간 10[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 41 / 351 | 시간 21[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 61 / 351 | 시간 31[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 81 / 351 | 시간 41[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 101 / 351 | 시간 51[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 121 / 351 | 시간 62[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 141 / 351 | 시간 73[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 161 / 351 | 시간 83[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 181 / 351 | 시간 93[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 201 / 351 | 시간 104[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 221 / 351 | 시간 114[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 241 / 351 | 시간 124[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 261 / 351 | 시간 136[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 281 / 351 | 시간 147[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 301 / 351 | 시간 157[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 321 / 351 | 시간 167[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 341 / 351 | 시간 178[s] | 손실 0.01\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "X 2013-02-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "O 2016-11-06\n",
      "---\n",
      "val acc 91.300%\n",
      "| 에폭 7 |  반복 1 / 351 | 시간 0[s] | 손실 0.03\n",
      "| 에폭 7 |  반복 21 / 351 | 시간 12[s] | 손실 0.02\n",
      "| 에폭 7 |  반복 41 / 351 | 시간 24[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 61 / 351 | 시간 35[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 81 / 351 | 시간 45[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 101 / 351 | 시간 56[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 121 / 351 | 시간 66[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 141 / 351 | 시간 76[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 161 / 351 | 시간 87[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 181 / 351 | 시간 97[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 201 / 351 | 시간 107[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 221 / 351 | 시간 117[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 241 / 351 | 시간 128[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 261 / 351 | 시간 139[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 281 / 351 | 시간 151[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 301 / 351 | 시간 162[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 321 / 351 | 시간 174[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 341 / 351 | 시간 185[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "O 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "O 2016-11-06\n",
      "---\n",
      "val acc 100.000%\n",
      "| 에폭 8 |  반복 1 / 351 | 시간 0[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 21 / 351 | 시간 10[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 41 / 351 | 시간 22[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 61 / 351 | 시간 32[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 81 / 351 | 시간 42[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 101 / 351 | 시간 53[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 121 / 351 | 시간 63[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 141 / 351 | 시간 73[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 161 / 351 | 시간 83[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 181 / 351 | 시간 94[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 201 / 351 | 시간 104[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 221 / 351 | 시간 114[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 241 / 351 | 시간 124[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 261 / 351 | 시간 134[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 281 / 351 | 시간 145[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 301 / 351 | 시간 155[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 321 / 351 | 시간 165[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 341 / 351 | 시간 175[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "O 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "O 2016-11-06\n",
      "---\n",
      "val acc 100.000%\n",
      "| 에폭 9 |  반복 1 / 351 | 시간 0[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 21 / 351 | 시간 10[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 41 / 351 | 시간 20[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 61 / 351 | 시간 30[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 81 / 351 | 시간 41[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 101 / 351 | 시간 51[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 121 / 351 | 시간 61[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 141 / 351 | 시간 71[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 161 / 351 | 시간 81[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 181 / 351 | 시간 92[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 201 / 351 | 시간 102[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 221 / 351 | 시간 112[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 241 / 351 | 시간 122[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 261 / 351 | 시간 132[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 281 / 351 | 시간 143[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 301 / 351 | 시간 153[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 321 / 351 | 시간 163[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 341 / 351 | 시간 173[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "O 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "O 2016-11-06\n",
      "---\n",
      "val acc 100.000%\n",
      "| 에폭 10 |  반복 1 / 351 | 시간 0[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 21 / 351 | 시간 10[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 41 / 351 | 시간 21[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 61 / 351 | 시간 31[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 81 / 351 | 시간 41[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 101 / 351 | 시간 51[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 121 / 351 | 시간 62[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 141 / 351 | 시간 72[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 161 / 351 | 시간 82[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 181 / 351 | 시간 92[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 201 / 351 | 시간 103[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 221 / 351 | 시간 113[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 241 / 351 | 시간 123[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 261 / 351 | 시간 133[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 281 / 351 | 시간 143[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 301 / 351 | 시간 153[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 321 / 351 | 시간 164[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 341 / 351 | 시간 174[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "O 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "O 2016-11-06\n",
      "---\n",
      "val acc 100.000%\n"
     ]
    }
   ],
   "source": [
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('date.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# 입력 문장 반전\n",
    "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hidden_size = 256\n",
    "batch_size = 128\n",
    "max_epoch = 10\n",
    "max_grad = 5.0\n",
    "\n",
    "model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1, batch_size=batch_size, max_grad=max_grad)\n",
    "    \n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model, question, correct, id_to_char, verbose, is_reverse=True)\n",
    "        \n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list.append(acc)\n",
    "    print('val acc %.3f%%' % (acc * 100))\n",
    "    \n",
    "model.save_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAe9UlEQVR4nO3de3xU9Z3/8dcnFyBcBISgEMCAUAS5iKZeilZFu1xsAXtbbe1Wa7Xtqm23XXZ13W378LePbX/r7mJ/W9bWh7W1rltrqyWpsiIoYtFqjRJAgoGACkm4BIRwC+T2+f0xExxCAhPIyZmZ834+HjyYc+bMzGfmMZn3zOec8/2auyMiItGVFXYBIiISLgWBiEjEKQhERCJOQSAiEnEKAhGRiMsJu4DOGjx4sBcWFoZdhohIWnnzzTd3uXt+e9elXRAUFhZSWloadhkiImnFzN7v6Dq1hkREIk5BICIScQoCEZGIUxCIiEScgkBEJOICO2rIzB4BPgnsdPeJ7VxvwI+B2cAh4GZ3fyuoeuRDi1ZVc/+SCmr21jNsQB7zZ4xj3tQC1RFyHakgVV4L1dG9dQR5+OgvgZ8Av+rg+lnA2Pi/S4AH4/9LgBatquaep9dS39gMQPXeeu55ei1At77BVUfqSZXXQnV0fx2BBYG7v2xmhSfYZC7wK4+Ng/2amQ0ws6Huvi2omgTuX1Jx9A3Vqr6xmfueKad3j+xuq+O+Z8o7qGMdPXNiHcvWAdLdweNLraOmO9B2CPUPr/MPL7ez/dFbOfzL4vXt1nH/korIBUFH741/WvQ2m2sPdFsdv3jlPdWRRB1d+R4N84SyAmBrwnJVfN1xQWBmtwO3A4wcObJbistUNXvr213/wcEGbn/szW6upr06GvnG4+F3CDt6nTJZR895/5Em/nN5ZbfV0dEUKarjWF35Hg0zCKydde0+ZXd/CHgIoKioSDPpnIZhA/KobucNlN+vJ7+4+aPdVsctv3yD2v1Hjls/pF9PHv3KxVj83WHxt4nZh28YO/rOsYTtWq+z47azhO1oc91nHnyVHfuOr6Nvrxz2HW7kjF65nX1qaWfVlj0sWLax/T8+oGBAHq/cPb3b6pn2oxfbfY+qjmMNG5DXZY8RZhBUASMSlocDNSHVEhnzZ4zju79dTXPLh3/2ebnZ3Dt7PBML+ndbHffOHn9M37O1jn+YPZ7xQ8/otjrumXV8HVkG+w83cfmPXuS2K0Zz87RC+mVgIKytqmPBsg28+M5OBvbOZc7koTy/fgeHG1uObpOXm838GeO6ta75M8a1+95QHcHVEWYQlAB3mtkTxHYS12n/QPBmTxrKPU+vgewsDjc2h3YkROvjhX1ERkd1jBnSlweWbeDfl27g56+8y21XjObLHyukb8+0G57rOOU1+3hg2QaeL99B/7xc5s8Yd/S5pcJRMqn+3sjEOiyoOYvN7NfAVcBgYAfwfSAXwN1/Gj989CfATGKHj97i7icdTa6oqMg16Nype2H9Dm59tJRHbi5i+nlnhV1Oylu9dS8PLNvA8opaBvbO5faPn8tfXXYOfdIwEDbs2M8DyzaweO12+vXK4bYrRnNLhv7akeOZ2ZvuXtTudek2eb2C4PTc9etVrNxYy5/vvZbcbJ1PmKxVW/bwwLKNrNhQy6A+PfjalaP50qWF5HXjkVanqnLnAX78wkaeWVNDnx45fGVaIbdePpr+vRUAUXKiIEi/rzVyyg4eaWJp+XY+c+FwhUAnTR05kEe/cjFvvr+HB5Zt4F8Wv8NDL2/m61eey02XnkOv3NQLhPd2HeT/vbCRRWXV9MrN5htXnsttV4xmYJ8eYZcmKUZBECFLy2M7AqN2fHxXuuicgTx26yWUvvcBC5Zt4J+fXc/PXt7MN648ly9cMjIlAmHrB4f4zxc38tRb1eRmG1+9YjRf+/hoBvXtGXZpkqIUBBFSXFZNwYA8Lho5MOxS0l5R4Zk8/tVLeX3zbhYs28B9z5Tz0xWbuOPqMfzlR0eEEgjVe+v5yYuV/LZ0K1lZxpcvK+TrV41mSL9e3V6LpBcFQUTsPnCElzfu4rYrRpOV1d4pHHIqLhk9iCduv4w/bYoFwvdL1vHgS5u4Y/oYPl80nJ45wQfC9rrDLFxeyRNvbMEwvnjJSP766jGcdYYCQJKjIIiIxWu30dzizL1gWNilZKTLzh3EpaMv5dVNu1mwdAP/tOhtHlxeyR3Tx/C5i0bQI6fr98ns3H+YB1/axOOvb8Hd+XzRCO64ekyXnmgk0aAgiIjishrGndWvW0/WihozY9qYwXzs3EGsrNzFgqUbuPf3b/Nfyzdx1/QxfOairtlJv+vAEX62YhOPvfY+jc3OZy8czp3TxzDizN5d8CwkihQEEbD1g0OUvr+n28+IjCoz44qx+Vw+ZjArNtSyYNlG7n56LQtfquSuq8dy/YUFpxQIHxxs4KGXN/Poq+9xpKmZ66cO55vXjOGcQX0CeBYSJQqCCPjDmtjIHXOmqC3UncyMq8YN4cqP5PNSRS0Llm3g755aEwuE6WOZd8EwcpIIhLpDjTy8cjOPrHyXQ43NzJkyjG9eM5Zz8/t2w7OQKFAQREDxqhouOmegWgchMTOuPm8IV43L54X1O1mwbAN/+9vVLFxeyV3TxzD3ggL+sLrmuCEEpo8fwiMr3+Xnf3yX/UeauG7yUL59zVjGntUv7KckGUZnFme4d7bvY+YDf+S+uefzV5cVhl2OEJsXYWn5DhYs28j6bfvI79uDvfWNNDZ/+LeYk2XkZhv1jS3MPP9svnXtWO3fkdOiM4sjrLishuws47pJQ8MuReLMjL84/2yuHX8Wz5dv587/WUVTy7FfyJpanJws45m7Lu/WUWElmjTOQAZraXFKymq4YuxgnVWagrKyjJkThx4zJHiiI00tCgHpFgqCDPbmlj1U763XuQMprqPj/nU+gHQXBUEGKy6rplduFp+YcHbYpcgJzJ8xjrw2Q1KEMQGKRJf2EWSoxuYWnl2zjU9MODsjJlPJZKkyAYpElz4hMtTKjbvYc6iRuTp3IC3Mm1qgD34JjVpDGaq4rJr+ebl8/CP5YZciIilOQZCBDjU08Xz5DmZPGhrIYGcikln0KZGBlpbv4FBDM/N0tJCIJEFBkIFKymoY2r8XHy08M+xSRCQNKAgyzJ6DDazYUMucKcM0AY2IJEVBkGGeXbuNphZnjtpCIpIkBUGGKSmrYcyQvkzQAGUikiQFQQap3lvPn9/7gHkXDMNMbSERSY6CIIP8YXXrBDQ6MUlEkqcgyCCLVlUzdeQARg7SBDQikjwFQYao2L6fd7bv15ASItJpCoIMUbK6OjYBzWQFgYh0joIgA7g7xWU1TBszmPx+moBGRDpHQZAB3tqyl6o99WoLicgpURBkgOKyanrmZPEX558VdikikoYCDQIzm2lmFWZWaWZ3t3P9SDNbbmarzGyNmc0Osp5M1DoBzbXjz6Jfr9ywyxGRNBRYEJhZNrAQmAVMAG40swltNvtH4El3nwrcAPxXUPVkqlcqd7H7YIPmJRaRUxbkL4KLgUp33+zuDcATwNw22zjQOhZCf6AmwHoyUklZDWf0yuHKcZqARkROTZBBUABsTViuiq9L9APgJjOrAhYDd7V3R2Z2u5mVmllpbW1tELWmpfqGZpas287sSUPpmZN98huIiLQjyCBob7Abb7N8I/BLdx8OzAYeM7PjanL3h9y9yN2L8vP1zbfVsvU7ONjQrJFGReS0BBkEVcCIhOXhHN/6uRV4EsDd/wT0AgYHWFNGKS6r4ewzenHJqEFhlyIiaSzIIHgDGGtmo8ysB7GdwSVtttkCXANgZuOJBYF6P0nYe6iBFRt28qkpQ8nWBDQichoCCwJ3bwLuBJYA64kdHbTOzO4zsznxzb4L3GZmq4FfAze7e9v2kbTjf9/eTmOzM/cCjTQqIqcnJ8g7d/fFxHYCJ677XsLlcmBakDVkqkWrqhmd34fzh2kCGhE5PTqzOA3VHJ2ApkAT0IjIaVMQpKFn1tTgDnM0tpCIdAEFQRoqLqthyogBFA7uE3YpIpIBFARppnLnftbV7NNIoyLSZRQEaaa4rIYsg09OGRp2KSKSIRQEaSRxApoh/XqFXY6IZAgFQRop27qXLR8c0k5iEelSCoI0UlxWQ4+cLGZMPDvsUkQkgygI0kRTcwvPrKnhmvOGcIYmoBGRLqQgSBOvbtrNrgMNGlJCRLqcgiBNFJfV0K9XDldpAhoR6WIKgjRwuDE2Ac2siWfTK1cT0IhI11IQpIEX1u/kwJEmtYVEJBAKgjRQXFbNkH49uXS0JqARka6nIEhxdYcaeamilk9NGaYJaEQkEAqCFPfcum00NLcwV/MSi0hAFAQpbtGqGkYN7sOkgv5hlyIiGUpBkMK21x3mtXd3M2fKME1AIyKBURCksNYJaNQWEpEgKQhSWHFZDZOH92d0ft+wSxGRDKYgSFGbag+wtrpOI42KSOAUBCmquKwGM/iUgkBEAqYgSEHuTklZNR87dxBnnaEJaEQkWAqCFLSmqo73dh9i7hQNKSEiwVMQpKDishp6ZGsCGhHpHgqCFNPc4vxhTQ1Xn5dP/zxNQCMiwVMQpJg/bdpN7f4jzNNIoyLSTRQEKaa4rJp+PXO4+rwhYZciIhGhIEghhxubee7t7czQBDQi0o0UBClk+Ts72X+kSUNKiEi3CjQIzGymmVWYWaWZ3d3BNp83s3IzW2dm/xNkPamuuKyGwX17cpkmoBGRbpQT1B2bWTawEPgEUAW8YWYl7l6esM1Y4B5gmrvvMbPINsbr6ht5sWInX7xkJDnZ+qEmIt0nyE+ci4FKd9/s7g3AE8DcNtvcBix09z0A7r4zwHpS2pJ122loatG8xCLS7ZIKAjN7ysyuM7POBEcBsDVhuSq+LtFHgI+Y2Stm9pqZzezg8W83s1IzK62tre1ECemjpKyGcwb1ZspwTUAjIt0r2Q/2B4EvABvN7Edmdl4St2lvJhVvs5wDjAWuAm4EHjazAcfdyP0hdy9y96L8/PwkS04fO/cd5tVNu5irCWhEJARJBYG7L3P3LwIXAu8BS83sVTO7xcw6Ov21ChiRsDwcqGlnm2J3b3T3d4EKYsEQKX9Ys40WhzlqC4lICJJu9ZjZIOBm4KvAKuDHxIJhaQc3eQMYa2ajzKwHcANQ0mabRcDV8fsfTKxVtLkT9WeEkrJqJhacwZghmoBGRLpfsvsIngb+CPQGPuXuc9z9N+5+F9Dup5e7NwF3AkuA9cCT7r7OzO4zsznxzZYAu82sHFgOzHf33af3lNLLu7sOsrqqTiONikhokj189Cfu/mJ7V7h7UUc3cvfFwOI2676XcNmB78T/RVJxWbUmoBGRUCXbGhqfuBPXzAaa2V8HVFNkxCagqeHSUYM4u78moBGRcCQbBLe5+97Whfhx/7cFU1J0vF29j827DmpICREJVbJBkGUJxzXGzxruEUxJ0VFcVk1utjFr4tCwSxGRCEt2H8ES4Ekz+ymxcwG+DjwXWFUR0NzilKyu4apxQ+jfWxPQiEh4kg2Cvwe+BnyD2IlizwMPB1VUFLy+eTc79x9RW0hEQpdUELh7C7Gzix8MtpzoKC6roU+PbK4df1bYpYhIxCUVBPFRQn8ITACOHt7i7qMDqiujHWlqZvHb2zQBjYikhGR3Fv+C2K+BJmJnAv8KeCyoojLdSxW17D/cpJFGRSQlJLuPIM/dXzAzc/f3gR+Y2R+B7wdYW8ZZtKqa+5dUUL23niyD3fsPh12SiEjSQXA4PgT1RjO7E6gGIjuJzKlYtKqae55eS31jMwAtDvcuWkdWVhbzpuqXgYiEJ9nW0LeJjTP0TeAi4Cbgy0EVlYnuX1JxNARa1Tc2c/+SipAqEhGJOekvgvjJY5939/nAAeCWwKvKQDV76zu1XkSku5z0F4G7NwMXmWZMOS3DBuR1ar2ISHdJtjW0Cig2sy+Z2adb/wVZWKaZP2McudnHZmlebjbzZ4wLqSIRkZhkg+BMYDcwHfhU/N8ngyoqE82bWsDo/L5kZxkGFAzI44efnqQdxSISumTPLNZ+gdO091ADm3Ye4LYrRnP3rGSmfBYR6R7Jnln8C46feB53/0qXV5Shnl+3g6YW57pJGmlURFJLsucRPJNwuRdwPcdPRC8n8MzabYw4M4+JBWeEXYqIyDGSbQ09lbhsZr8GlgVSUQbae6iBVyt3cesVo9DBVyKSapLdWdzWWGBkVxaSyVrbQp+cpCGnRST1JLuPYD/H7iPYTmyOAknCs2oLiUgKS7Y11C/oQjLV3kMNvKK2kIiksKRaQ2Z2vZn1T1geYGbzgisrc+hoIRFJdcnuI/i+u9e1Lrj7XjQEdVJa20KTCvqffGMRkRAkGwTtbZfsoaeR1doWmj1pqNpCIpKykg2CUjP7DzM718xGm9kC4M0gC8sEaguJSDpINgjuAhqA3wBPAvXAHUEVlSnUFhKRdJDsUUMHgbsDriWj6GghEUkXyR41tNTMBiQsDzSzJcGVlf7UFhKRdJFsa2hw/EghANx9D5qz+ISeXbuN4QPVFhKR1JdsELSY2dEhJcyskHZGI5WY1rbQdZN1tJCIpL5kg+BeYKWZPWZmjwErgHtOdiMzm2lmFWZWaWYd7mMws8+amZtZUZL1pLTny9UWEpH0kVQQuPtzQBFQQezIoe8SO3KoQ/FJ7xcCs4AJwI1mNqGd7foB3wRe71TlKezZNWoLiUj6SHZn8VeBF4gFwHeBx4AfnORmFwOV7r7Z3RuAJ4C57Wz3f4B/BQ4nWXNKO9oW0klkIpImkm0NfQv4KPC+u18NTAVqT3KbAmBrwnJVfN1RZjYVGOHuiRPfHMfMbjezUjMrra092cOG62hbaLLaQiKSHpINgsPufhjAzHq6+zvAuJPcpr2vw0d3MJtZFrCA2C+ME3L3h9y9yN2L8vPzkyw5HGoLiUi6STYIquLnESwClppZMSefqrIKGJGwPLzNbfoBE4GXzOw94FKgJJ13GKstJCLpKNkzi6+PX/yBmS0H+gPPneRmbwBjzWwUUA3cAHwh4T7rgMGty2b2EvC37l6adPUpRm0hEUlHnR5B1N1XJLldk5ndCSwBsoFH3H2dmd0HlLp7SWcfO9Ut1klkIpKGAh1K2t0XA4vbrPteB9teFWQtQdt7qIGVG3dx6+UaW0hE0supTl4vbbS2hWbrJDIRSTMKgi7S2haaPFxtIRFJLwqCLlB3qJGVG3W0kIikJwVBF1hSvl1tIRFJWwqCLqC2kIikMwXBaVJbSETSnYLgNKktJCLpTkFwmtQWEpF0pyA4DXWHGjW2kIikPQXBaXi+fDuNzWoLiUh6UxCchmfVFhKRDKAgOEWtbaHZaguJSJpTEJyi1raQJqgXkXSnIDhFaguJSKZQEJwCtYVEJJMoCE6BjhYSkUyiIDgFi9duo2BAHlPUFhKRDKAg6KS6Q42srNzFdZPVFhKRzKAg6CS1hUQk0ygIOkltIRHJNAqCTlBbSEQykYKgE9QWEpFMpCDoBLWFRCQTKQiSpLaQiGQqBUGS1BYSkUylIEiS2kIikqkUBEmoq4+1hWZPOlttIRHJOAqCJCwt3xEbcnrysLBLERHpcgqCJDy7pkZtIRHJWAqCk1BbSEQyXaBBYGYzzazCzCrN7O52rv+OmZWb2Roze8HMzgmynlPR2hbS0UIikqkCCwIzywYWArOACcCNZjahzWargCJ3nwz8DvjXoOo5Va1toQtGDAi7FBGRQAT5i+BioNLdN7t7A/AEMDdxA3df7u6H4ouvAcMDrKfT1BYSkSgIMggKgK0Jy1XxdR25Ffjf9q4ws9vNrNTMSmtra7uwxBNTW0hEoiDIIGjvK7S3u6HZTUARcH9717v7Q+5e5O5F+fn5XVjiibWeRKa2kIhksiCDoAoYkbA8HKhpu5GZXQvcC8xx9yMB1tMpdfWN/HFjrdpCIpLxggyCN4CxZjbKzHoANwAliRuY2VTgZ8RCYGeAtXSa2kIiEhWBBYG7NwF3AkuA9cCT7r7OzO4zsznxze4H+gK/NbMyMyvp4O66ndpCIhIVOUHeubsvBha3Wfe9hMvXBvn4p6q1LXTzxwrVFhKRjKczi9uhtpCIRImCoB1qC4lIlCgI2mhtC82aqKOFRCQaFARtfDjktNpCIhINCoI21BYSkahRECRQW0hEokhBkGCZ2kIiEkEKggTPqi0kIhGkIIhTW0hEokpBENfaFpqttpCIRIyCIK61LTRVbSERiRgFAWoLiUi0KQhQW0hEok1BQOwksmH9e6ktJCKRFPkgqKtv5OWNtcyeNFRtIRGJpMgHgdpCIhJ1kQ8CtYVEJOoiHQSxo4V2qS0kIpEW6SBYVr6DhuYWtYVEJNIiHQRqC4mIRDgIWttCs9QWEpGIi2wQtLaFNOS0iERdZINAbSERkZhIBsG+w2oLiYi0imQQHD1aaJLaQiIikQyCZ9eoLSQi0ipyQZDYFsrKUltIRCRyQaC2kIjIsSIXBGoLiYgcK1JBoLaQiMjxIhUEaguJiBwv0CAws5lmVmFmlWZ2dzvX9zSz38Svf93MCoOoY9Gqaqb96EW+8+Rqsgy27DoYxMOIiKSlwILAzLKBhcAsYAJwo5lNaLPZrcAedx8DLAD+b1fXsWhVNfc8vZbqvfUAtDj8w6K3WbSquqsfSkQkLQX5i+BioNLdN7t7A/AEMLfNNnOBR+OXfwdcY118qu/9Syqob2w+Zl19YzP3L6noyocREUlbQQZBAbA1Ybkqvq7dbdy9CagDBrW9IzO73cxKzay0tra2U0XUxH8JJLteRCRqggyC9r7Z+ylsg7s/5O5F7l6Un5/fqSKGDcjr1HoRkagJMgiqgBEJy8OBmo62MbMcoD/wQVcWMX/GOPJys49Zl5ebzfwZ47ryYURE0laQQfAGMNbMRplZD+AGoKTNNiXAl+OXPwu86O7H/SI4HfOmFvDDT0+iYEAeBhQMyOOHn57EvKltu1QiItGUE9Qdu3uTmd0JLAGygUfcfZ2Z3QeUunsJ8HPgMTOrJPZL4IYgapk3tUAf/CIiHQgsCADcfTGwuM267yVcPgx8LsgaRETkxCJ1ZrGIiBxPQSAiEnEKAhGRiFMQiIhEnHXx0ZqBM7Na4P1TvPlgYFcXlpPu9HocS6/Hh/RaHCsTXo9z3L3dM3LTLghOh5mVuntR2HWkCr0ex9Lr8SG9FsfK9NdDrSERkYhTEIiIRFzUguChsAtIMXo9jqXX40N6LY6V0a9HpPYRiIjI8aL2i0BERNpQEIiIRFxkgsDMZppZhZlVmtndYdcTFjMbYWbLzWy9ma0zs2+FXVMqMLNsM1tlZs+EXUvYzGyAmf3OzN6Jv08uC7umsJjZ38T/Tt42s1+bWa+wawpCJILAzLKBhcAsYAJwo5lNCLeq0DQB33X38cClwB0Rfi0SfQtYH3YRKeLHwHPufh4whYi+LmZWAHwTKHL3icSG0w9kqPywRSIIgIuBSnff7O4NwBPA3JBrCoW7b3P3t+KX9xP7I4/0ZA1mNhy4Dng47FrCZmZnAB8nNlcI7t7g7nvDrSpUOUBefAbF3hw/y2JGiEoQFABbE5ariPiHH4CZFQJTgdfDrSR0DwB/B7SEXUgKGA3UAr+It8oeNrM+YRcVBnevBv4N2AJsA+rc/flwqwpGVILA2lkX6eNmzawv8BTwbXffF3Y9YTGzTwI73f3NsGtJETnAhcCD7j4VOAhEcp+amQ0k1jkYBQwD+pjZTeFWFYyoBEEVMCJheTgZ+hMvGWaWSywEHnf3p8OuJ2TTgDlm9h6xluF0M/vvcEsKVRVQ5e6tvxJ/RywYouha4F13r3X3RuBp4GMh1xSIqATBG8BYMxtlZj2I7fApCbmmUJiZEev/rnf3/wi7nrC5+z3uPtzdC4m9L15094z81pcMd98ObDWzcfFV1wDlIZYUpi3ApWbWO/53cw0ZuuM80DmLU4W7N5nZncASYnv+H3H3dSGXFZZpwJeAtWZWFl/3D/H5pUUA7gIej39p2gzcEnI9oXD3183sd8BbxI62W0WGDjWhISZERCIuKq0hERHpgIJARCTiFAQiIhGnIBARiTgFgYhIxCkIRAJmZldpVFNJZQoCEZGIUxCIxJnZTWb2ZzMrM7OfxecoOGBm/25mb5nZC2aWH9/2AjN7zczWmNnv4+PSYGZjzGyZma2O3+bc+N33TRjj//H4maqY2Y/MrDx+P/8W0lOXiFMQiABmNh74S2Cau18ANANfBPoAb7n7hcAK4Pvxm/wK+Ht3nwysTVj/OLDQ3acQG5dmW3z9VODbxObDGA1MM7MzgeuB8+P388/BPkuR9ikIRGKuAS4C3ogPvXENsQ/sFuA38W3+G7jczPoDA9x9RXz9o8DHzawfUODuvwdw98Pufii+zZ/dvcrdW4AyoBDYBxwGHjazTwOt24p0KwWBSIwBj7r7BfF/49z9B+1sd6IxWdob7rzVkYTLzUCOuzcRmzTpKWAe8FwnaxbpEgoCkZgXgM+a2RAAMzvTzM4h9jfy2fg2XwBWunsdsMfMroiv/xKwIj6vQ5WZzYvfR08z693RA8bnhOgfH/Dv28AFQTwxkZOJxOijIifj7uVm9o/A82aWBTQCdxCbmOV8M3sTqCO2HwHgy8BP4x/0iSN0fgn4mZndF7+Pz53gYfsBxfEJ0Q34my5+WiJJ0eijIidgZgfcvW/YdYgESa0hEZGI0y8CEZGI0y8CEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJuP8PjM9ac9p1khIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig8-26.png\" width=600>\n",
    "\n",
    "기본 seq2seq는 쓸모가 없고 peeky와 어텐션은 비슷한 정확도를 보였다. 학습 속도는 어텐션이 우세했다.\n",
    "\n",
    "현실의 시계열은 훨씬 복잡하므로 어텐션이 더욱 우세할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.3 어텐션 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Attention 계층의 인스턴스 변수 attention_weight에 각 시각의 어텐션 가중치를 이용하면 입력 문장과 출력 문장의 단어 대응 관계를 2차원 맵으로 그릴 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAANmklEQVR4nO3db6ie9X3H8fcnJ9aYIms9VWisXQMLrk6w1kxsYVJaGWkRpB1CxMK2SsPATtuxB322dWMPCn2agdkMdjBSSv+MUrpWKWtlTG0Tq90RKw11tallqUetOEHPSb57cN+HnMT7nHNd6X3d5xfzfsHB8+ebX77H5Hxy3b/rzzdVhSSpXVs2uwFJ0voMaklqnEEtSY0zqCWpcQa1JDVu6xCLJvFSEm3ouuuu61x75MiRATuRmvBcVV066QsZ4vI8g1pdnDx5snPt3NzcYH14iaoacaSqdk/6glsfktQ4g1qSGmdQS1LjDGpJapxBLUmNM6glqXEbBnWSg0mOJ1mYRUOSpNN1OaK+D9gzcB+SpDVsGNRV9SDw/Ax6kSRNMLVbyJPsA/ZNaz1J0sjUgrqqDgAHwFvIJWmavOpDkhpnUEtS47pcnncIeAi4MsmxJHcM35YkacWGe9RVddssGpEkTebWhyQ1zqCWpMYZ1JLUOINakhpnUEtS4waZQq52JelV32fw644dO3qtfeGFF3auXVxc7LX2/Px8r3qpZR5RS1LjDGpJapxBLUmNM6glqXEGtSQ1zqCWpMYZ1JLUuE5BneTuJAtJnkjy6aGbkiSd0uV51FcDnwSuB64Bbk6ya+jGJEkjXY6o3w08XFWvVNUy8H3go8O2JUla0SWoF4Abk8wn2Q58BLjizKIk+5IcTnJ42k1K0vmsy4SXJ5N8HngAeBl4HFieUOcUckkaQKeTiVV1b1W9t6puBJ4HfjpsW5KkFZ2enpfksqo6nuSdwMeA9w3bliRpRdfHnH41yTywBNxZVS8M2JMkaZVOQV1VfzR0I5KkybwzUZIaZ1BLUuMMaklqnEEtSY1Ln+GlnRf1hhdtsj5/r/sO/JUGcqSqdk/6gkfUktQ4g1qSGmdQS1LjDGpJapxBLUmNM6glqXEGtSQ1zqCWpMZ1nUL+mfEE8oUkh5JsG7oxSdJIlynklwN3Abur6mpgDtg7dGOSpJGuWx9bgYuSbAW2A88O15IkabUNg7qqfgl8AXgG+BXwm6q6/8w6p5BL0jC6bH28FbgF2AnsAN6c5ONn1lXVgaravdZDRSRJZ6fL1sdNwNNV9euqWgK+Brx/2LYkSSu6BPUzwA1Jtmf0PMgPAU8O25YkaUWXPepHgK8AjwL/Pf41BwbuS5I05uAAvSE5OEDnIAcHSNK5yqCWpMYZ1JLUOINakhq3dbMbkIbQ5wRh3xPqnnzUrHlELUmNM6glqXEGtSQ1zqCWpMYZ1JLUOINakhpnUEtS47oMDtiW5AdJHh8PuP3cLBqTJI10ueHlVeCDVfVykguA/0zy71X18MC9SZLoENQ1um3r5fGHF4zffIypJM1Ipz3qJHNJHgOOAw+MhwmcWeNwW0kaQK/BAUneAnwd+MuqWlinziNunTN81ocaMZ3BAVX1IvA9YM8UmpIkddDlqo9Lx0fSJLmI0VTynwzdmCRppMtVH28HvphkjlGwf7mqvjlsW5KkFV2u+vgxcO0MepEkTeCdiZLUOINakhpnUEtS4wxqSWqcQS1JjRtkCnkStm7ttnSfu7yWlpZ69TE/P9+rvo/FxcXOtX3vfNNs3X777b3qvTPx9Yb8fzI3N9er/pJLLulce+utt/Za+5577ulc2zev1uMRtSQ1zqCWpMYZ1JLUOINakhpnUEtS4wxqSWqcQS1JjTOoJalxBrUkNc6glqTGTe0W8iT7gH3TWk+SNDK1oK6qA8ABgC1btvhwC0maks5bH0nuTPLY+G3HkE1Jkk7pfERdVfuB/QP2IkmawJOJktQ4g1qSGmdQS1LjDGpJapxBLUmNM6glqXEGtSQ1LkNMyN6yZUt1nULeR981T5482bn2ueee67X2xRdf3Lm274Rmp5ZL56UjVbV70hc8opakxhnUktQ4g1qSGmdQS1LjDGpJapxBLUmNM6glqXGdgjrJniRPJTma5LNDNyVJOmXDoE4yx2hgwIeBq4Dbklw1dGOSpJEuR9TXA0er6mdV9RrwJeCWYduSJK3oEtSXA79Y9fGx8edOk2RfksNJDnsLtCRNT5eHZ0x6UMXrktgp5JI0jC5H1MeAK1Z9/A7g2WHakSSdqUtQ/xDYlWRnkjcBe4FvDNuWJGnFhlsfVbWc5FPAd4A54GBVPTF4Z5IkoNseNVX1LeBbA/ciSZrAOxMlqXEGtSQ1zqCWpMYZ1JLUuOlPoGU0nHVpaWnq6/Zdc8uW7v8O9RlW29eQd2r2+R6h38BfgOXl5c61Qww0ngWHD6t1HlFLUuMMaklqnEEtSY0zqCWpcQa1JDXOoJakxhnUktQ4g1qSGtdluO3BJMeTLMyiIUnS6bocUd8H7Bm4D0nSGjYM6qp6EHh+Br1IkiaY2sMZkuwD9k1rPUnSyNSCevUU8iQ+tUaSpsSrPiSpcQa1JDWuy+V5h4CHgCuTHEtyx/BtSZJWbLhHXVW3zaIRSdJkbn1IUuMMaklqnEEtSY0zqCWpcZs+NrrPBOi+05/7TNx+6aWXeq29c+fOzrWLi4u91u6j71Txbdu29ao/VyeL9+FUcbXOI2pJapxBLUmNM6glqXEGtSQ1zqCWpMYZ1JLUOINakhpnUEtS4wxqSWqcQS1JjXO4rSQ1zuG2ktS4zlsfSe5M8tj4bceQTUmSTul8RF1V+4H9A/YiSZrAk4mS1DiDWpIaZ1BLUuMMaklqnEEtSY0zqCWpcQa1JDVu00dMtzIBen5+vlf90tLSQJ30c+LEiV71c3NzA3UiaSgeUUtS4wxqSWqcQS1JjTOoJalxBrUkNc6glqTGGdSS1LgNgzrJwSTHkyzMoiFJ0um6HFHfB+wZuA9J0ho2DOqqehB4fga9SJImcAq5JDXOKeSS1Div+pCkxhnUktS4LpfnHQIeAq5McizJHcO3JUlaseEedVXdNotGJEmTufUhSY0zqCWpcQa1JDXOoJakxhnUktS4TZ9C3opWpor31XeqeN+p70l61UuaPo+oJalxBrUkNc6glqTGGdSS1DiDWpIaZ1BLUuMMaklqXKegTrInyVNJjib57NBNSZJO6fI86jlgP/Bh4CrgtiRXDd2YJGmkyxH19cDRqvpZVb0GfAm4Zdi2JEkrugT15cAvVn18bPy50yTZl+RwksPTak6S1O1ZH5Me9vC6B0Y4hVyShtHliPoYcMWqj98BPDtMO5KkM3UJ6h8Cu5LsTPImYC/wjWHbkiSt6DLcdjnJp4DvAHPAwap6YvDOJEkApO/ziTst6h51s3wetdSsI1W1e9IXvDNRkhpnUEtS4wxqSWqcQS1JjTOoJalxQ00hfw74+Rmfe9v48131qR9y7ZZ6+a3XXucqjqb73qS1W+rFtWe79mb08rtrVlfVTN6Aw0PVD7l2S724tn/2rn3+/dlXlVsfktQ6g1qSGjfLoD4wYP2Qa/etd+03ztp96137jbN23/pBexnkFnJJ0vS49SFJjTOoJalxMw3qJP81y9/vfJXkYJLjSRY61jcxZf4s+r47yUKSJ5J8eoPaz4zrFpIcSrJtndptSX6Q5PHxr/lc3+9FmqaZBnVVvX+Wv99myshmvWK5D9jTpbCxKfP30b3vq4FPMhq+fA1wc5Jda9ReDtwF7K6qqxk9V33vOsu/Cnywqq4B3gPsSXJD129CmrZZH1G/3KHm35IcGR/J7Nug9l1JnkzyT+P6+5NctEH9wqqP/zrJ306jlzP6+UfgUU4fYba67u+T3L3q439IctdG63dVVQ8Cz3csb2bKfM++3w08XFWvVNUy8H3go+vUbwUuSrIV2M464+RqZOXv6gXjN8+6a9O0uEf9iaq6DtgN3JVkfoP6XcD+qvoD4EXgTzaxF4ArgX+pqmur6szb6FfcC/wpwPioey/wr9No+Cx0mjLfoAXgxiTzSbYDH2GNfxir6pfAF4BngF8Bv6mq+9dbPMlckseA48ADVfXIVLuXemgxqO9K8jjwMKMfvIkvZ1d5uqoeG79/BHjXJvYC8POqeni9gqr6H2AxybXAHwM/qqrF37bZs9RpynxrqupJ4PPAA8C3gceB5Um1Sd7K6FXCTmAH8OYkH99g/RNV9R5Gw5yvH2+1SJuiqaBO8gHgJuB94/3BHwFrnvQZe3XV+ydY/0FTy5z+Pa93QulsegH4vw41AP8M/Bnw58DBjr9mCOfslPmqureq3ltVNzLaMvnpGqU3MfoH/ddVtQR8Deh0vqSqXgS+R8e9c2kITQU18DvAC1X1SpLfB6Z9Aud/gcvGL5cvBG7exF6+zuiH/w8ZDQ7eLGc1ZT7Jd8cn6TZNksvG/30n8DHg0BqlzwA3JNme0eMDPwQ8uc66lyZ5y/j9ixgF/U+m2bvUx1CPOV3LRi+pvw38RZIfA08x2nKY3m9etZTk74BHgKdZ/4dv6F5eS/IfwItVdWKaayc5BHwAeFuSY8DfVNW9a/TRe8r8eF/99+h+4m/qfY99dXzeYAm4s6pemFRUVY8k+QqjE7zLjF4drXcL79uBL46viNkCfLmqvtn7G5KmZGa3kI9/oB6tqrWfuXoeGYfdo8CtVbXWS/YmjfdrP1FVf7XZvUjng5lsfSTZATzE6Mz7eW98nfJR4LvnWkgDVNWCIS3Njg9lkqTGtXYyUZJ0BoNakhpnUEtS4wxqSWqcQS1Jjft/sxhu9gwwvZoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dataset import sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from attention_seq2seq import AttentionSeq2seq\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    sequence.load_data('date.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# 입력 문장 반전\n",
    "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hidden_size = 256\n",
    "\n",
    "model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "model.load_params()\n",
    "\n",
    "_idx = 0\n",
    "def visualize(attention_map, row_labels, column_labels):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pcolor(attention_map, cmap=plt.cm.Greys_r, vmin=0.0, vmax=1.0)\n",
    "\n",
    "    ax.patch.set_facecolor('black')\n",
    "    ax.set_yticks(np.arange(attention_map.shape[0])+0.5, minor=False)\n",
    "    ax.set_xticks(np.arange(attention_map.shape[1])+0.5, minor=False)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xticklabels(row_labels, minor=False)\n",
    "    ax.set_yticklabels(column_labels, minor=False)\n",
    "\n",
    "    global _idx\n",
    "    _idx += 1\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "np.random.seed(1984)\n",
    "for _ in range(5):\n",
    "    idx = [np.random.randint(0, len(x_test))]\n",
    "    x = x_test[idx]\n",
    "    t = t_test[idx]\n",
    "\n",
    "    model.forward(x, t)\n",
    "    d = model.decoder.attention.attention_weights\n",
    "    d = np.array(d)\n",
    "    attention_map = d.reshape(d.shape[0], d.shape[2])\n",
    "\n",
    "    # 출력하기 위해 반전\n",
    "    attention_map = attention_map[:,::-1]\n",
    "    x = x[:,::-1]\n",
    "\n",
    "    row_labels = [id_to_char[i] for i in x[0]]\n",
    "    column_labels = [id_to_char[i] for i in t[0]]\n",
    "    column_labels = column_labels[1:]\n",
    "\n",
    "    visualize(attention_map, row_labels, column_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 어텐션에 관한 남은 이야기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.1 양방향 RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "양방향 LSTM에서는 역방향도 처리하는 LSTM 계층을 추가해서 각 시각마다 두 LSTM 계층의 은닉 상태를 연결시킨 벡터를 최종 은닉 상태로 처리한다(연결 이외에도, 합하거나 평균하는 방법도 있다).\n",
    "\n",
    "양방향으로 처리하게 되면 은닉 상태 벡터에 좌, 우 양쪽 방향의 균형 잡힌 정보를 인코딩할 수 있다는 이점이 있다.\n",
    "\n",
    "구현은 단순히 입력 단어를 반대로 나열해서 입력하는 LSTM 계층을 하나 더 만든 다음 정방향으로 처리하는 계층의 출력과 연결해주면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeBiLSTM:\n",
    "    def __init__(self, Wx1, Wh1, b1,\n",
    "                 Wx2, Wh2, b2, stateful=False):\n",
    "        self.forward_lstm = TimeLSTM(Wx1, Wh1, b1, stateful)\n",
    "        self.backward_lstm = TimeLSTM(Wx2, Wh2, b2, stateful)\n",
    "        self.params = self.forward_lstm.params + self.backward_lstm.params\n",
    "        self.grads = self.forward_lstm.grads + self.backward_lstm.grads\n",
    "\n",
    "    def forward(self, xs):\n",
    "        o1 = self.forward_lstm.forward(xs)\n",
    "        o2 = self.backward_lstm.forward(xs[:, ::-1])\n",
    "        o2 = o2[:, ::-1]\n",
    "\n",
    "        out = np.concatenate((o1, o2), axis=2)\n",
    "        return out\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        H = dhs.shape[2] // 2\n",
    "        do1 = dhs[:, :, :H]\n",
    "        do2 = dhs[:, :, H:]\n",
    "\n",
    "        dxs1 = self.forward_lstm.backward(do1)\n",
    "        do2 = do2[:, ::-1]\n",
    "        dxs2 = self.backward_lstm.backward(do2)\n",
    "        dxs2 = dxs2[:, ::-1]\n",
    "        dxs = dxs1 + dxs2\n",
    "        return dxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.2 Attention 계층 사용 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig8-32.png\" width=700>\n",
    "\n",
    "이번 예시에서는 Attention 계층의 출력이 다음 시각의 LSTM 계층에 입력되도록 연결했다. 이전에 직접 구현한 경우는 Affine 계층에서 맥락 벡터를 이용한 반면 이 경우에는 LSTM 계층에서 맥락 벡터를 이용한다.\n",
    "\n",
    "구현 관점에서는 LSTM과 Affine 계층 사이에 Attention 계층을 삽입하는 것이 쉽다. 최종 정확도는 실험해봐야 알 수 있겠지만 큰 차이가 없을 것이라고 판단된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.3 seq2seq 심층화와 skip 연결"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig8-33.png\" width=700>\n",
    "\n",
    "일반적으로 Encoder과 Decoder의 LSTM 계층을 동일한 수로 구성한다. 이외에도 여러 방식으로 심층화할 수 있다.\n",
    "\n",
    "<img src=\"./images/fig8-34.png\" width=300>\n",
    "\n",
    "층을 깊게 할 때 기울기가 잘 흐를 수 있도록 하는 방법으로 **skip 연결**이 있다. skip 연결은 단순히 설명하자면 계층을 건너뛰는 연결이다. skip 연결은 LSTM의 출력과 LSTM을 통과하지 않은 출력의 잔차의 원소별 덧셈을 해준다. 덧셈은 역전파 시 기울기를 그대로 흘려보낼 수 있게 해준다.\n",
    "\n",
    "층을 깊게 하면 여전히 오버피팅 문제가 발생할 수 있기 때문에 일반화 성능을 유지해주기 위해서 드롭아웃과 가중치 공유 등의 기술을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 어텐션 응용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.1 구글 신경망 기계 번역(GNMT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기계 번역의 역사\n",
    "\n",
    "규칙 기반 - 용례 기반 - 통계 기반 - 신경망 기계 번역(NMT)\n",
    "\n",
    "<img src=\"./images/fig8-35.png\" width=700>\n",
    "\n",
    "#### GNMT의 특징\n",
    "\n",
    "- seq2seq: Encoder, Decoder, Attention으로 구성\n",
    "- LSTM 다층화\n",
    "- 양방향 LSTM(첫번째 계층만)\n",
    "- skip 연결\n",
    "- GPU 분산 학습\n",
    "- 양자화: 낮은 빈도의 단어 처리나 추론 고속화 위해\n",
    "\n",
    "GNMT의 정확도는 사람이 한 번역의 정확도와 매우 가까워지고 있다. 하지만 여전히 부족한 부분도 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.2 트랜스포머"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN은 이전 시각의 계산 결과를 이용해서 순서대로 계산해야 하기 때문에 병렬 계산이 기본적으로 불가능하다.\n",
    "\n",
    "병렬 계산을 위한 RNN 연구 중 유명한 것이 'Attention is all you need'라는 논문에서 제안한 트랜스포머 모델이다.\n",
    "\n",
    "<img src=\"./images/fig8-37.png\" width=600>\n",
    "\n",
    "트랜스포머의 핵심은 셀프어텐션이다. 셀프어텐션은 하나의 시계열 내에서 원소 간 대응 관계를 구하는 방법이다. 두 개의 서로 다른 시계열을 입력으로 받아서 대응 관계를 보는 것이 아닌 하나의 시계열을 입력으로 받는다.\n",
    "\n",
    "<img src=\"./images/fig8-38.png\" width=600>\n",
    "\n",
    "트랜스포머에서는 RNN 대신 어텐션을 사용한다. Encoder와 Decoder는 모두 셀프어텐션을 사용한다. 그리고 은닉층이 1개이고 활성화 함수로 ReLU를 이용한 완전연결계층 신경망(피드포워드 신경망)을 다음 계층으로 쌓는다. 위의 그림에서 회색으로 둘러쌓은 부분을 N겹으로 쌓았다.\n",
    "\n",
    "실제 트랜스포머에서는 skip 연결과 계층 정규화, 위치 인코딩, 다수의 어텐션을 이용하는 등 더욱 복잡하지만 그림에서는 설명을 위해 축약된 모델을 표현하고 있다.\n",
    "\n",
    "트랜스포머를 이용하면 계산량을 줄이고 GPU를 이용한 병렬 계산의 혜택도 누릴 수 있다. 뿐만 아니라 정확도도 향상시킬 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.3 뉴럴 튜링 머신(NTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴럴 튜링 머신의 컨셉은 RNN 외부에 정보 저장용 메모리 기능을 배치하고, 어텐션을 이용하여 그 메모리로부터 필요한 정보를 읽거나 쓰는 것이다.\n",
    "\n",
    "<img src=\"./images/fig8-41.png\" width=700>\n",
    "\n",
    "#### 처리 방식 설명\n",
    "\n",
    "LSTM 계층이 컨트롤라가 되어 NTM의 주된 처리를 한다. LSTM 계층의 은닉 상태를 Write Head 계층이 받아서 필요한 정보를 메모리에 쓴다. 다음으로 Read Head 계층이 메모리로부터 중요한 정보를 읽어 다음 시각의 LSTM 계층으로 전달한다. 메모리 조작은 콘텐츠 기반 어텐션과 위치 기반 어텐션을 이용한다.\n",
    "\n",
    "콘텐츠 기반 어텐션은 지금까지 본 어텐션과 동일하고, 입력으로 주어진 벡터와 비슷한 벡터를 메모리로부터 찾아내는 용도로 이용된다.\n",
    "\n",
    "위치 기반 어텐션은 이전 시각에서 주목한 메모리의 위치를 기준으로 전후로 이동하는 용도로 사용된다. 1차원 합성곱 연산을 통해 구현된다.\n",
    "\n",
    "메모리 조작은 이미 언급한 어텐션에서 선택 작업을 미분 가능한 문제로 대체하는 방식과 유사한 방식을 이용한다.\n",
    "\n",
    "NTM의 성과는 seq2seq으로만으로 풀지 못 했던 복잡한 문제에서 효과를 발휘하고 있다는 점이다. 특히 주어진 동작을 학습하는 것이 아닌 알고리즘 자체를 학습할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
